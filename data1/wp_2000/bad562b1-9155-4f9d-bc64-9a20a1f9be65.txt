Un superordinateur, ou supercalculateur, est un ordinateur conçu pour atteindre les plus hautes performances possibles avec les techniques connues lors de sa conception, en particulier en ce qui concerne la vitesse de calcul.
La science des superordinateurs est appelée "calcul haute performance" (en anglais : High-Performance Computing ou HPC).

Historique
Superodinateur CDC 6600 avec sa console. Lancé en 1964.
Les premiers superordinateurs (ou supercalculateurs) apparaissent dans les années 1960. En 1961, IBM développe l'IBM Stretch ou IBM 7030, dont une unité est exploitée en France en 1963.
À cette époque, et jusque dans les années 1970, le plus important constructeur mondial de superordinateurs est la société Control Data Corporation (CDC), avec son concepteur Seymour Cray. Par la suite, Cray Research, fondée par Seymour Cray après son départ de CDC, prend l'avantage sur ses autres concurrents, jusqu'aux alentours de l'année 1990. Dans les années 1980, à l'image de ce qui s'était produit sur le marché des micro-ordinateurs des années 1970, de nombreuses petites sociétés se lancèrent sur ce marché, mais la plupart disparaissent dans le "crash" du marché des superordinateurs, au milieu des années 1990.
Ce que désigne le terme superordinateur varie avec le temps, car les ordinateurs les plus puissants du monde à un moment donné tendent à être égalés, puis dépassés, par des machines d'utilisation courante plusieurs années après. Les premiers superordinateurs CDC étaient de simples ordinateurs mono-processeurs (mais possédant parfois jusqu'à dix processeurs périphériques pour les entrées-sorties) environ dix fois plus rapides que la concurrence. Dans les années 1970, la plupart des superordinateurs adoptent un processeur vectoriel, qui effectue le décodage d'une instruction une seule fois pour l'appliquer à toute une série d'opérandes.
Un supercalculateur Cray-2, inventé par Seymour Cray et lancé à partir de 1985.
C'est seulement vers la fin des années 1980 que la technique des systèmes massivement parallèles est adoptée, avec l'utilisation dans un même superordinateur de milliers de processeurs. De nos jours, certains de ces superordinateurs parallèles utilisent des microprocesseurs de type "RISC", conçus pour des ordinateurs de série, comme les PowerPC ou les PA-RISC. D'autres supercalculateurs utilisent des processeurs de moindre coût, de type "CISC", microprogrammés en RISC dans la puce électronique (AMD ou Intel) : le rendement en est un peu moins élevé, mais le canal d'accès à la mémoire - souvent un goulet d'étranglement - est bien moins sollicité.
Au XXIe siècle, les superordinateurs sont le plus souvent conçus comme des modèles uniques par des constructeurs informatiques "traditionnels" comme International Business Machines (IBM), Hewlett-Packard (HP), ou Bull, qu'ils aient derrière eux une longue tradition en la matière (IBM) ou qu'ils aient racheté dans les années 1990 des entreprises spécialisées, alors en difficulté, pour acquérir de l'expérience dans ce domaine.

Utilisation
Total de la puissance de calcul des 500 meilleurs supercalculateurs mondiaux, de 1993 à 2008 (selon le classement TOP500).
Les superordinateurs sont utilisés pour toutes les tâches qui nécessitent une très forte puissance de calcul, comme les prévisions météorologiques, l'étude du climat (à ce sujet, voir les programmes financés par le G8-HORCs), la modélisation d'objets chimiques (calcul de structures et de propriétés, modélisation moléculaire, etc.), les simulations physiques (simulations aérodynamiques, calculs de résistance des matériaux, simulation d'explosion d'arme nucléaire, étude de la fusion nucléaire, etc.), la cryptanalyse ou les simulations en finance et en assurance (calcul stochastique).
Les institutions de recherche civiles et militaires comptent parmi les plus gros utilisateurs de superordinateurs.
En France, on trouve ces machines dans les centres nationaux de calculs universitaires, tels que l'Institut du développement et des ressources en informatique scientifique (IDRIS), le Centre informatique national de l'enseignement supérieur (CINES), mais aussi au Commissariat à l'énergie atomique et aux énergies alternatives (CEA) ou dans certaines grandes entreprises, comme Total, EDF ou encore Météo-France.

Conception
Le superordinateur FSL JET du Forecast Systems Laboratory (en) de la National Oceanic and Atmospheric Administration (2000).
Les superordinateurs tirent leur supériorité sur les ordinateurs conventionnels à la fois grâce à : leur architecture, en "pipeline" (exécution d'une instruction identique sur une longue série de données) ou parallèle (nombre très élevé de processeurs fonctionnant chacun sur une partie du calcul), qui leur permet d'exécuter plusieurs tâches simultanément ;; de composants électroniques rapides (structure de type serveurs lame utilisant des processeurs multi-coeur ou des cartes graphiques dédiées au calcul scientifique de dernière génération, de la mémoire vive et des équipements de stockage de masse - disque dur - reliés à la fibre optique en grande quantité, etc.) associés à un système d'exploitation dédié (comme Linux, majoritairement utilisé actuellement).
Une lame IBM BladeCenter (en) HS20.
Ils sont presque toujours conçus spécifiquement pour un certain type de tâches (le plus souvent des calculs numériques scientifiques : calcul matriciel ou vectoriel) et ne cherchent pas de performance particulière dans d'autres domaines.
L'architecture mémorielle des supercalculateurs est étudiée pour fournir en continu les données à chaque processeur afin d'exploiter au maximum sa puissance de calcul. Les performances supérieures de la mémoire (meilleurs composants et meilleure architecture) expliquent pour une large part l'avantage des superordinateurs sur les ordinateurs classiques.
Leur système d'entrée-sortie (bus) est conçu pour fournir une large bande passante, la latence étant moins importante puisque ce type d'ordinateur n'est pas conçu pour traiter des transactions.
Comme pour tout système parallèle, la loi d'Amdahl s'applique, les concepteurs de superordinateurs consacrant une partie de leurs efforts à éliminer les parties non parallélisables du logiciel et à développer des améliorations matérielles pour supprimer les goulets d'étranglement restants.

Principaux obstacles techniques
Supercalculateur IBM Blue Gene-Q de l'Argonne National Laboratory (2013).
D'une part, les superordinateurs ont souvent besoin de plusieurs mégawatts de puissance électrique. Cette alimentation doit aussi être de qualité. En conséquence, ils produisent une grande quantité de chaleur et doivent donc être refroidis pour fonctionner normalement. Le refroidissement (par exemple à air) de ces ordinateurs pose souvent un problème important de climatisation.
D'autre part, les données ne peuvent circuler plus vite que la vitesse de la lumière entre deux parties d'un ordinateur. Lorsque la taille d'un superordinateur dépasse plusieurs mètres, le temps de latence entre certains composants se compte en dizaines de nanosecondes. Les éléments sont donc disposés pour limiter la longueur des câbles qui relient les composants. Sur le Cray-1 ou le Cray-II, par exemple, ils étaient disposés en cercle.
De nos jours, ces ordinateurs sont capables de traiter et de communiquer de très importants volumes de données en très peu de temps. La conception doit assurer que ces données puissent être lues, transférées et stockées rapidement. Dans le cas contraire, la puissance de calcul des processeurs serait sous-exploitée (goulot d'étranglement).

Historique des records:
Top 20 des supercalculateurs dans le monde en juin 2013.;
Tableau de la vitesse de calcul (Rmax) du top des superordinateurs ; échelle logarithmique sur 60 ans.;
Distribution par pays des supercalculateurs du top 500 en novembre 2015.
.
Historique des records en France
Le supercalculateur Jade installé par le GENCI au Centre informatique national de l'enseignement supérieur (CINES), à Montpellier, France (2010). Le supercalculateur Occigen installé par le GENCI au CINES, à Montpellier (2015).
En 1993, l'Institut de Physique du Globe de Paris (IGP) opère un ordinateur CM-5-128 qui utilise des processeurs SuperSPARC, il est classé 25e au TOP500. Trois ans plus tard, en 1996, l'Institut du développement et des ressources en informatique scientifique (IDRIS) parvient à atteindre la 12e place mondiale avec le T3E construit par Cray.
À la mi-2002, le plus puissant des supercalculateurs français se classe 4e au TOP500, c'est le TERA basé sur des processeurs Alpha à 1 GHz (AlphaServer SC45) et développé par Hewlett-Packard ; il appartenait au Commissariat à l'énergie atomique (CEA). En janvier 2006, le TERA-10 de Bull lui succède, il génère une puissance de calcul de 60 téraFLOPS et se placera au 5e rang mondial du TOP500.
En juin 2008, l'IDRIS et son Blue Gene-P Solution d'IBM affiche, selon le test LINPACK, une puissance de 120 téraflops et remporte la 10e place.
En novembre 2009, la première machine française a pour nom Jade. De type "SGI Altix (en)" elle est basée au Centre informatique national de l'enseignement supérieur (CINES) de Montpellier. Ce supercalculateur se classe au 28e rang mondial avec 128 téraflops au test LINPACK. Peu après, la configuration de la machine Jade est complétée pour atteindre une performance de 237 téraflops. La machine passe en juin 2010 au 18e rang du TOP500. C'est alors le troisième système informatique européen et le premier français, il est destiné à la recherche publique.
En novembre 2010, le record français est détenu par le TERA-100 de Bull. Installé au CEA à Bruyères-le-Châtel pour les besoins de la simulation militaire nucléaire française, avec une performance de 1 050 téraflops, cette machine se hisse au 6e rang mondial et gagne le 1er rang européen. Elle est constituée de 17 296 processeurs Intel Xeon 7500 dotés chacun de huit coeurs et connectés par un réseau de type InfiniBand.
En mars 2012, Curie, un système conçu par Bull pour le GENCI, installé sur le site du Très Grand Centre de Calcul (TGCC) à Bruyères-le-Châtel, dispose d'une puissance de 1,359 pétaflops. Il devient le supercalculateur le plus puissant de France en prenant la 9e place du classement mondial. Il est conçu pour délivrer 2 pétaflops.
En janvier 2013, les systèmes Ada et Turing construits par IBM sont installés à l'IDRIS d'Orsay. La somme de leur puissance dépasse le pétaflops. Ces deux machines sont à la disposition des chercheurs. En mars 2013, le supercalculateur Pangea détenu par la société Total est inauguré, il devient le système le plus performant jamais installé en France. Sa puissance de calcul s'élève à 2,3 pétaflops. Équivalant 27 000 ordinateurs de bureau réunis, il obtient la 11e place mondiale.
En janvier 2015, le système Occigen, conçu par Bull, Atos technologies, pour le GENCI et installé sur le site du CINES, il est doté d'une puissance de 2,1 pétaflops. Il se situait en 26e position au classement mondial du TOP500 de novembre 2014.
En mars 2016, Total annonce avoir triplé la capacité de calcul de son supercalculateur Pangea, passant à une puissance de calculs de 6,7 pétaflops en pics de performance et de 5,28 pétaflops en puissance utilisable. Cela lui permet de retrouver le 11e rang au TOP500 et le place ainsi en tête du secteur industriel mondial.

Systèmes d'exploitation pour superordinateurs
Transition des systèmes d'exploitation des superordinateurs d'Unix (en bleu pâle) vers Linux (en vert). Linux est le système d'exploitation équipant la très grande majorité des 500 supercalculateurs les plus puissants de la planète (92,4 % en juin 2012).; Unix perd progressivement du terrain face à Linux, mais occupe encore une place de choix sur le marché des supercalculateurs (5 %).; Windows n'est exécuté que par deux des 500 supercalculateurs les plus puissants de la planète, soit 0,4 %.; BSD, quant à lui, ne dispose que d'une seule représentation dans le top 500, soit 0,2 %.; Enfin, les autres configurations ("Mixed", soit un ensemble de plusieurs types de systèmes d'exploitation) représentent 4,6 %.

Supercalculateurs et jeux de réflexion

Échecs
En 1997, le supercalculateur Deep Blue d'IBM bat le champion du monde d'échecs Garry Kasparov lors d'un match revanche. C'est la première fois qu'un champion du monde est battu par un supercalculateur en match de plusieurs parties.
Auparavant, en mai 1994, à Munich, le programme Fritz 3, tournant sur un ordinateur avec un monoprocesseur Pentium à 90 MHz, gagna une partie de blitz dans un tournoi contre Kasparov et, en août 1994, lors du premier tour du grand Prix d'Intel à Londres, le champion du monde affronta Chess Genius 2.9 (tournant sur un Pentium à 100 MHz) en semi-rapide (30 min. la partie) et perdit 0.5-1.5.
En 2010, Veselin Topalov confirme utiliser pour sa préparation au championnat du monde d'échecs 2010 le superordinateur Blue Gene-P doté alors de 8792 processeurs.

Go