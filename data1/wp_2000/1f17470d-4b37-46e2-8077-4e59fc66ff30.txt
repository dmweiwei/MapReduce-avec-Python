Les sciences cognitives constituent une discipline scientifique ayant pour objet la description, l'explication, et le cas échéant la simulation des mécanismes de la pensée humaine, animale ou artificielle, et plus généralement de tout système complexe de traitement de l'information capable d'acquérir, conserver, utiliser et transmettre des connaissances. Les sciences cognitives reposent sur l'étude et la modélisation de phénomènes aussi divers que la perception, l'intelligence, le langage, la mémoire, l'attention, le raisonnement, les émotions ou même la conscience. Les sciences cognitives utilisent conjointement des données issues des six sous-disciplines qui la composent : les neurosciences, la linguistique computationnelle, l'anthropologie cognitive, la psychologie cognitive, la philosophie de la cognition et l'intelligence artificielle. Nées dans les années 1950 aux États-Unis dans le cadre des progrès sur l'intelligence artificielle financées par la recherche militaire et particulièrement DARPA , les sciences cognitives recoupent les enjeux liés à la cognition artificielle et à la cognition naturelle.
En France, cette discipline a mis en place des sociétés savantes comme l'Association pour la Recherche Cognitive (ARCo) ou des associations comme la Fresco. Le CNRS a fondé récemment l'Institut des Sciences Cognitives en 1992 à l'initiative de Marc Jeannerod (du nom du médecin français). Cet institut rebaptisé plus tard Institut Marc Jeannerod est un institut du CNRS en partenariat avec l'Université de Lyon et l'Institut Jean-Nicod avec des membres de l'Université Paris Sciences et Lettres (l'EHESS et l'ENS Ulm). Les sciences cognitives comprennent une science fondamentale et ses applications industrielles. On distingue, en effet, au sein des sciences cognitives : une science fondamentale, dite science de la cognition, dont les spécialistes, parfois appelés cogniticiens, sont réunis en sociétés savantes et publient dans des revues scientifiques internationales dédiées. Son principe essentiel est le suivant : l'utilisation de l'ordinateur pour manipuler les symboliques,; un secteur applicatif industriel du domaine de l'ingénierie de la connaissance : la cognitique.
Il est à noter que le singulier cognitive science est d'usage courant dans les pays anglophones.
Les spécialistes des sciences cognitives (recherche et cognitique) sont appelés cogniticiens.

Histoire des sciences cognitives
Il est d'usage de dater la naissance des sciences cognitives de 1956. En effet, cette année voit s'organiser la toute première conférence consacrée à l'intelligence artificielle et à son application à la psychologie de la cognition, à laquelle participent les informaticiens Allen Newell, John McCarthy et Marvin Minsky, le mathématicien Claude Shannon, l'économiste et psychologue Herbert Simon, le linguiste Noam Chomsky, les psychologues George Miller et John Swets, les neurobiologistes David Hubel et Torsten Wiesel. L'année 1956 est aussi riche en publications fondamentales pour le domaine des sciences cognitives.
Quelques années auparavant pourtant, les conférences Macy, organisées à New York par la fondation éponyme à partir de 1942, avaient rassemblé les mathématiciens John von Neumann, Norbert Wiener, Claude Shannon, le neurophysiologiste Warren McCulloch, les anthropologues Margaret Mead et Gregory Bateson, le psychiatre Milton Erickson dans le but de créer une science générale du fonctionnement de l'esprit. En outre, au sortir de la Seconde Guerre mondiale, la recherche en ce qui n'était pas encore identifié comme l'intelligence artificielle bénéficiait de soutiens importants en provenance de l'armée, notamment la DARPA américaine.

Disciplines

Linguistique cognitive et grammaire générative
La linguistique formelle et plus particulièrement les travaux de Noam Chomsky ont eu une influence décisive au moment de l'émergence des sciences cognitives à la fin des années 1950. Chomsky s'est notamment élevé contre la conception du langage comme un ensemble d'"habitudes" apprises par observation et conditionnement. Contre cette vision béhavioriste, défendue entre autres, par B. F. Skinner, Chomsky défendit l'idée d'une "faculté de langage" s'appuyant sur des dispositions innées : observant que durant l'enfance, on n'est exposé qu'à un trop petit nombre de situations de langage pour pouvoir en inférer les règles sous-jacentes - c'est l'argument dit de "la pauvreté du stimulus", Chomsky propose que la compétence linguistique humaine s'appuie, pour se développer, sur une connaissance innée (et implicite) d'une grammaire universelle dont on retrouve la structure formelle dans toutes les langues humaines naturelles.
Héritières des interrogations philosophiques sur le rôle du langage dans la pensée (voir aussi ci-dessous) et prolongeant les théories de Roman Jakobson sur les fonctions non purement communicatives du langage, les sciences cognitives s'intéressent non seulement aux processus mentaux de production du langage mais aussi au rôle de ce dernier dans les opérations mentales. Les idées de Chomsky ont ainsi été reprises et développées au-delà de la linguistique par le philosophe Jerry Fodor, dans ses fameuses thèses sur la modularité de l'esprit, notion selon laquelle certaines opérations mentales (comme l'application des règles de grammaire) se déroulent de façon automatique et autonome, et le mentalais, une métaphore d'un langage intérieur dans lequel seraient traduites les opérations mentales.
À la frontière avec l'anthropologie, le rôle du langage dans les représentations mentales est reposé. Les anthropologues Brent Berlin et Paul Kay contestent l'hypothèse Sapir-Whorf selon laquelle le langage et plus précisément les catégories linguistiques conditionneraient plus ou moins fortement les représentations mentales. S'appuyant sur une étude comparée des termes de couleur à travers les langues, Berlin et Kay défendent au contraire l'idée que cette apparente diversité culturelle dans le lexique est en réalité le produit d'une même structure hiérarchique dans l'organisation de la perception et de la représentation des couleurs ; selon leur travaux, c'est donc l'esprit qui conditionne le langage et non l'inverse.
Chercheurs: Noam Chomsky; Gilles Fauconnier; George Lakoff; John Langshaw Austin; Ray Jackendoff; John Searle; Paul Grice; Dan Sperber; Leonard Talmy.
. Notions: Grammaire universelle; Compétence et performance (Générativisme); Module lexical (Générativisme).
.
Philosophie analytique et philosophie de l'esprit
Frege révolutionne la logique classique en introduisant le concept de dénotation dans son article Sens et Dénotation (Sinn und Bedeutung). Le sens de "étoile du matin" (a) est différent de celui de "étoile du soir" (b) puisque leurs réalisations acoustiques ou signitives diffèrent : "La différence de sens correspond à une différence du mode de donation de l'objet désigné" néanmoins ils dénotent la même réalité : la planète Vénus d'où (a) - (b) a une valeur de connaissance car ce n'est pas tous les jours qu'on découvre qu'une étoile est une planète. Ainsi cit. "La dénotation d'"étoile du soir" et d'"étoile du matin" serait la même, mais leur sens serait différent". Ce qui a permis d'actualiser le signe de Saussure qui refusait d'y attribuer la référence au monde. Il a introduit la quantification dans la logique formelle. On oppose le quantificateur universel : "Tous les hommes sont mortels" au quantificateur existentiel "Il existe au moins un homme mortel". Il a fondé le calcul des prédicats.
Penseurs: René Descartes; Baruch Spinoza; Gottlob Frege; Ludwig Wittgenstein; Bertrand Russell; Willard Van Orman Quine; Edmund Husserl.
. Penseurs (suite): Gilbert Ryle; Daniel Dennett; Jerry Fodor; Hilary Putnam; Donald Davidson; John Searle; Peter Strawson.
. Notions: Problème corps-esprit, dualisme et monisme; Matérialisme; Fonctionnalisme; Modularité de l'esprit; Qualia et Chambre chinoise; Intentionnalité; Enaction; Négation.
.
Intelligence artificielle
Chercheurs: Allen Newell; Herbert Simon; Marvin Minsky; John McCarthy; Seymour Papert; Warren McCulloch; Walter Pitts.
. Notions: Système expert, ontologie (informatique); Architecture cognitive et modèle cognitif; Reconnaissance de formes; Système multi-agents; Métaheuristique; Moteur d'inférence; Neurone formel et réseau de neurones.
. Réalisations: Perceptron; ELIZA; General Problem Solver; Soar.
.
Neurosciences
Chercheurs: Jean-Pierre Changeux; Antonio Damasio; Stanislas Dehaene; Gerald Edelman; Henri Laborit; Marc Jeannerod; David Hubel; Brenda Milner.
. Disciplines: Neurosciences cognitives; Neuropsychologie; Psychophysiologie; Neurosciences computationnelles.
. Outils et techniques: Électrophysiologie; Imagerie cérébrale fonctionnelle: IRMf, TEP; EEG, MEG (Potentiels évoqués, rythmes cérébraux).; IRMf, TEP; EEG, MEG (Potentiels évoqués, rythmes cérébraux); Stimulation magnétique transcranienne (TMS); Neuropharmacologie.
. Théories et concepts: Théories du neurone grand-mère, du neurone miroir; Dominance cérébrale.
.
Psychologie cognitive
La psychologie cognitive concerne les processus d'élaboration et d'utilisation des connaissances chez l'être humain. Bien que l'on puisse trouver de nombreux précurseurs comme Hermann Ebbinghaus, Jean Piaget ou Frederic Bartlett, elle n'apparaît véritablement qu'à la fin des années 1950. Elle se caractérise par un retour des "variables intermédiaires" entre le stimulus et la réponse, bannies par le béhaviorisme, et l'utilisation de nouvelles méthodes pour tenter d'observer ces variables en évitant les problèmes rencontrés par l'introspection au début du XXe siècle.
Chercheurs: Alan Baddeley; George Miller; Eleanor Rosch; Donald Broadbent; Daniel Kahneman; Hermann von Helmholtz; Gustav Fechner.
. Chercheurs (suite): Ulric Neisser; Jerome Bruner; Frederic Bartlett; Hermann Ebbinghaus; Lev S. Vygotsky.
. Grandes fonctions cognitives et manipulations expérimentales: Perception : illusion; Mémoire; Langage : effets Stroop, McGurk; Raisonnement : biais cognitif; Émotions et cognition sociale : théorie de l'esprit; Autres grandes fonctions : décision, calcul, attention; Théorie du prototype.
.
Courants et concepts

Cognitivisme
Le cognitivisme est l'un des principaux courants des sciences cognitives avec le connexionnisme, ce dernier tendant aujourd'hui à le supplanter. Il est fondé sur l'idée que l'esprit est un système de traitement symbolique de l'information (métaphore de l'ordinateur), autrement dit, un système opérant sur des représentations en fonction de leurs propriétés syntaxiques plutôt qu'en vertu de leur signification. Inspirés par les résultats de Turing, de nombreux chercheurs ont en outre admis que ce type de traitement pouvait être réalisé par des machines complètement différentes du point de vue physique, et que la simulation et la modélisation informatique pouvaient donc fournir de nouveaux moyens d'étudier le fonctionnement de l'esprit, rejoignant ainsi le projet de la cybernétique qui consiste à intégrer dans un même cadre théorique l'étude des systèmes naturels et artificiels.

Réseaux de neurones et connexionnisme
Issu de la cybernétique, le connexionnisme fait partie des sciences cognitives depuis l'origine. Après une éclipse au cours des années 1970, il regagne aujourd'hui en importance avec les progrès de l'imagerie cérébrale et des neurosciences. Partageant avec le cognitivisme l'idée de représentation, il rejette en revanche l'hypothèse d'un fonctionnement cognitif symbolique. Dans une perspective connexionniste, la cognition est le produit d'un calcul parallèle opéré par des entités sub-symboliques (neurone formel ou non) et la signification découle de l'état du réseau formé par ces entités à un moment donné.

Processus cognitifs

Attention
L'attention est grosso modo la capacité à se concentrer sur certains stimuli ou, au contraire, l'impossibilité de traiter plus d'une certaine quantité d'informations à un moment donné. Autre définition : l'attention est la capacité de focaliser la conscience sur un "domaine" ou "champ de conscience" afin d'en extraire de l'information. Ces champs de conscience peuvent être physique, mental, émotionnel, spirituel, passé, présent, futur et dans des dimensions incomprises, souvent appelées aussi irrationnelles.

Mémoire
La mémoire permet de retenir des informations pour les réutiliser ultérieurement. À l'inverse de l'apprentissage béhavioriste, la notion de mémoire insiste sur les structures et processus intermédiaires entre l'acquisition de ces informations et leurs conséquences sur le comportement.
Elle fait l'objet de nombreux travaux en sciences cognitives, aussi bien du point de vue de la psychologie ou des neurosciences que de la modélisation. Les chercheurs se sont ainsi attachés à mettre en évidence les différentes structures composant la mémoire en se basant à la fois sur des expériences et sur les dysfonctionnements observés chez des patients cérébro-lésés.
Apparu dans les années 1960, le modèle modal de la mémoire a été l'un des plus influents. Il distingue le registre sensoriel (grande quantité d'informations sous forme visuelle pendant quelques millisecondes), la mémoire à court terme (nombre limité d'éléments sous forme verbale pendant quelques secondes) et la mémoire à long terme (informations sémantiques, en pratique sans limite de durée ou de capacité).
La notion de mémoire de travail a été présentée par Baddeley et Hitch en 1974. Ce modèle et d'autres plus récents comme celui de Cowan mettent en évidence les liens entre attention et mémoire. La mémoire de travail a ainsi pour rôle non seulement de contenir des informations en provenance des systèmes sensoriels mais aussi des informations extraites de la mémoire à long terme pour être utilisées par les processus de raisonnement et de prise de décision.
Dans le domaine de la mémoire à long terme, plusieurs distinctions ont été proposées comme celles entre mémoire épisodique (auto-biographique) et mémoire déclarative (connaissances générales) par Endel Tulving, entre mémoire sémantique et mémoire procédurale (gestes, comportements, savoir-faire) par John Anderson et entre mémoire explicite (utilisée de façon consciente et contrôlée) et mémoire implicite (automatique). De nombreuses recherches portent également sur les représentations mentales qui organisent ces informations.
De leur côté, les neurosciences ont également cherché à identifier les structures cérébrales réalisant ces différentes fonctions et à décrire les processus biologiques permettant l'apprentissage et l'encodage des informations. Le phénomène de potentialisation à long terme explique notamment comment la stimulation répétée de certaines connexions neuronales les rend plus susceptibles de s'activer à l'avenir en réponse à un stimulus similaire (même partiellement).
Enfin, de nombreux travaux portent sur les processus d'encodage, de stockage et de récupération. Parmi les principaux résultats on peut citer la courbe de l'oubli d'Ebbinghaus, les notions d'effet de récence et de primauté ou encore l'amorçage. Enfin, plusieurs expériences soulignent le rôle de la mémoire dans l'expertise (ainsi les bons joueurs d'échecs ne diffèrent pas des débutants par leur vitesse de traitement mais par l'organisation des informations sur le jeu).
Un certain nombre de modèles de la mémoire dit "à traces" tendent à se développer dans la droite ligne du courant connexionniste. Il s'agit de théories profondément dynamiques cherchant à expliquer les conceptions modularistes comme émergentes d'un système complexe et non cloisonné qui conserverait toutes les informations sous formes de traces. Ces traces ne seraient pas forcément localisées sur le plan cérébral mais réparties et se définiraient par un grand ensemble de facteurs sémantiques, émotionnels, moteurs, etc.

Informations complémentaires

Voir aussi

Articles connexes: Histoire de la psychologie cognitive; Psychologie cognitive; Traitement de l'information.