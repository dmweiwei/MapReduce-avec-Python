WebRTC (Web Real-Time Communication, littéralement "communication en temps réel pour le Web") est une interface de programmation (API) JavaScript actuellement au stade de brouillon (Draft) développée au sein du W3C et de l'IETF. C'est aussi un canevas logiciel avec des implémentations précoces dans différents navigateurs web pour permettre une communication en temps réel. Le but du WebRTC est de lier des applications comme la voix sur IP, le partage de fichiers en pair à pair en s'affranchissant des modules d'extensions propriétaires jusqu'alors nécessaires.
L'API repose sur une architecture triangulaire puis pair à pair dans laquelle un serveur central est utilisé pour mettre en relation deux pairs désirant échanger des flux de médias ou de données qui échangent ensuite sans autre relais. Cette architecture et la pile de protocoles utilisée posent des questions de sécurité et d'utilisation en relation avec d'autres technologies (comme les NAT ou les pare-feux) qui sont pour la plupart en cours de résolution par l'IETF et le W3C.
La technologie WebRTC étant assez récente, son intégration au sein des différents navigateurs est encore inégale ; bien que cela soit partiellement résolu par l'utilisation d'extensions propriétaires comme celle de Temasys.

Historique
Les échanges directs entre navigateurs ne sont pas une nouveauté introduite par le W3C et l'IETF mais les recherches et implémentations précédentes n'étaient pas standard (à cause de l'utilisation d'appliquettes propriétaires telles qu'Adobe Flash ou Microsoft ActiveX) et souvent mal documentées. Ces protocoles et plugins furent à la source de difficultés d'interopérabilité et de mise à jour pour les sites utilisant ces systèmes. Bien que ces implémentations permettaient une utilisation allant jusqu'à la visioconférence (telle que celle proposée par Adobe avec le Real Time Media Flow Protocol (en)), elles reposaient sur des plugins propriétaires et étaient donc dépourvues de standards.
Les applications internet riches étant perçues comme une évolution des pages web statiques, elles ont rapidement offert la possibilité d'animer les textes et les dessins présentés par le navigateur mais aussi de réaliser des fonctionnalités de glisser-déposer ou encore de flux (audio et vidéo) bidirectionnel. Cependant, si les applications riches sont, en partie au moins, exécutées par le navigateur, elles n'impliquent des communications qu'entre ce dernier et un (ou parfois plusieurs) serveur(s) web.
WebRTC est une technologie permettant les communications directes (i.e. sans passer par un serveur web) et en temps réel entre plusieurs navigateurs soutenue par Google, Mozilla et Opera au sein des standards du World Wide Web Consortium (W3C), dont les premières ébauches sont apparues en mai 2011. Afin d'en assurer le développement, une liste dédiée a été créée au sein du W3C dès avril 2011 ainsi qu'un groupe de travail au sein de l'IETF en mai 2011.
Cependant, ces initiatives s'opposent à Microsoft qui a soumis une proposition concurrente CU-RTC-WEB (en) le 8 août 2012.
Le standard qui établira le WebRTC n'étant pas encore complet, il peut encore subir de fortes modifications. Toute expérimentation est ainsi encouragée afin d'obtenir des retours d'expérience. L'API est basée sur des travaux préliminaires du WHATWG (qui se basaient sur l'API ConnectionPeer et sur les travaux issus des laboratoires d'Ericsson).
Le groupe de travail espère une évolution suffisante des spécifications à travers : les échanges d'entrées-sorties au sein du groupe RTCWEB d'IETF pour définir les protocoles pouvant permettre les communications en temps-réel au sein des différents navigateurs web ;; le respect de la vie privée : des intrusions pouvant se faire en accédant à des parties locales de l'ordinateur (caméra, micro...) ou en espionnant depuis l'extérieur les données échangées ;; les discussions techniques sur les canaux d'échange de données (quels qu'ils soient) entre particuliers ;; les retours d'expériences venant d'autres groupes et individus.

Description générale de la norme
Architecture d'une application WebRTC
L'architecture de l'API WebRTC repose sur une construction triangulaire impliquant un serveur et deux pairs. Les deux navigateurs téléchargent depuis un serveur une application JavaScript vers leur contexte local. Le serveur est utilisé comme point de rendez vous afin de coordonner les échanges entre navigateurs jusqu'à ce que la connexion directe entre navigateurs soit établie. L'application téléchargée utilise l'API WebRTC pour communiquer avec le contexte local. Le but est d'avoir une application cliente en JavaScript et HTML5 interagissant avec le navigateur au travers de l'API WebRTC.
Les flux d'échange entre navigateurs peuvent rencontrer divers serveurs qui se chargeront de modifier, traduire ou gérer le signal au besoin, permettant par exemple la traversée de pare-feux, proxys ou NAT.
Afin d'établir une connexion utilisant le standard WebRTC, les navigateurs A et B doivent être connectés simultanément à la page du service et télécharger la page HTML ainsi que le code JavaScript permettant de maintenir la connexion ouverte par HTTPS ou socket. Lorsque le navigateur A souhaite établir la connexion avec B, l'API instancie un objet PeerConnection qui, une fois créé, permet d'établir des flux de médias ou de données. Il est aussi nécessaire, pour une vidéoconférence par exemple, que les utilisateurs A et B acceptent le partage de leur caméra et-ou de leur microphone.
Établissement d'une connexion entre deux clients utilisant WebRTC: 1 : A demande au serveur une connexion avec B.; 2 : Le serveur relaie la demande de A à B.; 3 : Si B accepte, il envoie une demande de connexion à A.; 4 : Le serveur relaie la demande à A.; 5 et 6 : Les PeerConnection bidirectionnelles sont établies.
Une fois cet objet PeerConnection créé par A, le navigateur envoie au serveur un paquet contenant les informations sur les médias partagés ainsi qu'une empreinte liant la connexion à A. Le serveur va décoder ce paquet et identifier qu'il s'agit d'une communication à destination de B et enverra donc un signal à B. B est notifié du souhait de A d'établir une connexion et accepte ou non sa requête. Si elle est acceptée, le même processus a lieu entre B et A cette fois afin d'établir la connexion bidirectionnelle. Une fois celle-ci établie, les flux de médias ou de données peuvent être ajoutés à la connexion librement.
Dans le cadre par exemple d'un streaming vidéo en peer-to-peer entre navigateurs, l'utilisateur télécharge depuis un serveur les métadonnées de la vidéo qu'il souhaite regarder ainsi qu'une liste de paires disponibles et ayant tout ou partie de la vidéo. L'établissement d'une connexion avec les paires permet, par le flux de données, le téléchargement des morceaux de la vidéo qui sont réassemblés après vérification de leur intégrité puis lancement de la vidéo dans un lecteur HTML5.
L'API webRTC s'appuie sur des standards existants comme STUN, ICE, TURN, DTLS ou encore SRTP, technologies en parties issues du projet libjingle.

PeerConnection
L'API RTCPeerconnection représente le lien établi avec un navigateur distant, reposant sur le protocole UDP (habituellement une autre instance de la même application JavaScript s'exécutant sur le client distant). Afin d'établir cette connexion en pair à pair, il est nécessaire de s'appuyer sur un canal de communication établi par un serveur web et utilisant par exemple un objet XMLHttpRequest ou une WebSocket. Mozilla et Google en ont réalisé une démonstration technique en février 2013.
Pour obtenir une connexion, l'une des paires doit obtenir les informations locales (telles que les protocoles supportés pour l'audio ou la vidéo). Cette étape est permise par l'API via Session Description Protocol. SDP se base sur la RFC 3264 de l'IETF définissant une approche requête - réponse. Lors de l'établissement d'une session, une paire crée une requête qui décrit ce qu'il désire faire et l'autre répond en spécifiant les options qui ont été sélectionnées. Néanmoins, l'utilisation de SDP est en cours de remplacement au sein de la norme WebRTC par le protocole JSEP, notamment à cause des problèmes posés par le format de transmission de SDP, le blob d'information.
Dans le cadre de WebRTC, l'échange de ces requêtes et réponses par SDP se fait par un mécanisme laissé au choix de l'implémentation (typiquement un serveur Web utilisant une socket).
Ce processus utilisant SDP permet la négociation à la fois pour RTP (transport de médias) et pour SCTP (permettant le transport de données).
Afin d'assurer la continuité de la connexion en cas de conversion d'adresse par NAT et éviter le blocage par les pare-feux (notamment en entreprise), l'objet PeerConnection utilise les protocoles UDP, STUN et ICE.
Une fois cette connexion en pair à pair établie, chaque partie peut établir des MediaStreams ou DataStreams l'utilisant.

Data channels
Structure de la pile de protocoles utilisée par WebRTC dans un échange de données.
L'API DATA channels offre un moyen d'échange de données génériques bidirectionnel et pair à pair. Cette composante de webRTC permet l'échange de données telles que des images ou du texte. Une première démonstration par Mozilla a eu lieu en novembre 2012.
Ces canaux de données sont créés entre paires en utilisant l'objet PeerConnection. Ces données autres que les flux médias sont échangées via le protocole SCTP , lui-même encapsulé dans DTLS. Cette solution permet au flux de données d'être intégré dans le même paquet que les flux de médias et donc de partager le même numéro de port pour les échanges.
SCTP supporte nativement plusieurs flux de données de façon bidirectionnelle (jusqu'à 65536 dans chaque direction) au sein d'une association SCTP et gère les priorités. De cette façon, il est possible de favoriser les messages de haute priorité face aux gros objets à priorité basse. Chaque flux représente une connexion logique unidirectionnelle.
Afin d'assurer la confidentialité et l'authenticité des paquets SCTP échangés, chaque flux repose sur le protocole DTLS.
Au sein d'un canal de données, les applications peuvent transmettre des messages de façon ordonnée ou désordonnée. L'ordre de remise est préservé uniquement dans le cas d'une transmission de paquets ordonnés envoyés sur le même lien de données.
Un flux de données est créé lorsque l'une des paires appelle une méthode CreateDataChannel pour la première fois après avoir créé un objet PeerConnection. Chaque appel suivant à CreateDataChannel créera un nouveau flux de données au sein de la connexion SCTP existante.
Le protocole DTLS n'a pas pour seul rôle d'encapsuler les paquets SCTP. Dans le cadre d'un multiplexage avec des flux médias, le protocole DTLS encapsule la gestion des clés et la négociation des paramètres pour le protocole SRTP, utilisé pour la gestion des flux médias. Il y a donc dépendance du flux média vis-à-vis du flux de données.

Flux Media
Structure de la pile de protocoles utilisée par WebRTC dans un échange de médias.
Un MediaStream est une représentation d'un flux de données spécifique audio ou vidéo. Il permet la prise en charge des actions sur le flux média telles que l'affichage, l'enregistrement et l'envoi à une paire distante. Un MediaStream peut être local ou distant. L'API MediaStream gère les flux audio et vidéo et indique à l'application qu'elle doit donner accès à la caméra, aux haut-parleurs et au microphone ;
Afin d'être utilisé, un MediaStream local doit demander l'accès aux ressources multimédia de l'utilisateur via la fonction getUserMedia. L'application spécifie le type de média (audio ou vidéo) auquel elle souhaite accéder et le navigateur autorise ou refuse l'accès à la ressource demandée. Une fois que le média n'est plus utilisé, l'application peut révoquer son propre accès avec la méthode stop sur le flux média local.
Les flux médias sont transportés par le biais du protocole RTP, utilisable sur tout protocole de transport implémentant une abstraction de datagram (UDP par exemple). La confidentialité, l'authentification des messages et la protection contre les répétitions sont apportées par l'utilisation sécurisée de RTP, SRTP.
La gestion des clés pour SRTP est assurée par DTLS et donc le flux de données. Il est donc impossible d'avoir un flux média indépendant d'un flux de données là où l'inverse est envisageable.
Il est possible d'associer plusieurs flux médias sur une même connexion SRTP qui utiliseront des ressources médias différentes ou non. Dans ce cas, les sources de chaque flux sont clairement identifiées comme des SSRC.

Multiplexage media - data
L'API WebRTC prévoit le multiplexage de flux données ou média reposant sur une seule connexion de niveau transport. Ce multiplexage fait que les trois protocoles STUN, SRTP et DTLS coexistent au même niveau du modèle et qu'il est nécessaire de démultiplexer les paquets arrivants. Pour cela, le premier octet indiquant la nature du contenu UDP sert à déterminer de quel protocole il s'agit. Une valeur de 0 ou 1 indique un paquet STUN, une valeur entre 20 et 63 indique un paquet DTLS une valeur de 128 à 191 indique un paquet SRTP.
L'intérêt principal de ce multiplexage est qu'en partageant un même paquet de niveau transport, les flux de médias et de données passent plus facilement des NAT ou pare-feux en évitant, par exemple, qu'un paquet portant un flux de média ne soit bloqué alors qu'un paquet de données passe.

Spécifications techniques
À partir de mars 2012, le brouillon de travail de l'IETF WebRTC requiert au minimum les codecs audio suivants : PCMA-PCMU (RFC 3551) ;; Telephone Event (RFC 4733) comme le code DTMF ;; Opus (RFC 6716) que toutes les applications (coté client) doivent prendre en charge.
Les codecs vidéo ne sont pas encore définis mais doivent répondre à certains critères. Pour être retenu, un codec doit, entre autres, supporter au minimum 10 images par seconde (fps) et jusqu'à 30 ; il doit également supporter une résolution minimale de 320x240 pixels ; en ce qui concerne le codec VP8, il doit être en mesure de supporter l'algorithme bilinéaire du traitement des images et n'appliquer aucun filtre de reconstruction.

Problèmes posés par WebRTC et solutions potentielles

Sécurité des applications
Plusieurs problèmes de sécurité se posent lors de l'utilisation de WebRTC : L'application JavaScript (le code utilisant WebRTC) peut être téléchargée depuis n'importe quel site sans consentement de l'utilisateur.; L'exploitation de ressources média locales (par exemple les caméras et microphones) doit requérir l'approbation de l'utilisateur.; La confidentialité et l'authentification doivent être garanties dans tout échange pour éviter les attaques telles que l'attaque de l'homme du milieu.; Les informations privées de l'utilisateur ne doivent pas être dévoilées à des tiers sans le consentement de celui-ci.
Si certains de ces problèmes sont inhérents à toute communication sur Internet, d'autres problèmes ont été résolus par l'implémentation de WebRTC. Ainsi les échanges de médias sont sécurisés par le protocole SRTP.

Gestion de la perte de paquets
Le protocole UDP étant déconnecté et n'utilisant pas de système de vérification de réception des paquets (contrairement au protocole TCP par exemple), la perte de paquets est un problème pouvant se poser lors des transmissions en pair à pair de flux médias. Deux méthodes se présentaient afin de limiter la perte de paquets dus aux problèmes de réseaux : NACK (en) qui permet de signaler à l'émetteur une réception échouée ou l'absence de transmission ;; FEC, un code de contrôle qui permet au récepteur de vérifier que la totalité des paquets est arrivée correctement ;; RPS (Reference Picture Selection).
Lors de l'envoi d'un flux média, l'émetteur découpe le flux et calcule une somme de contrôle (FEC) qui est envoyée avec ces paquets. À la réception, les FEC sont recalculés pour vérifier l'absence d'erreurs et les données stockées dans une mémoire tampon. Si des paquets manquent, ils sont redemandés.
Dans le cadre de l'API WebRTC, une solution hybride entre NACK et FEC a été implémentée, accompagnée de contrôles temporels afin d'équilibrer la qualité de la vidéo, sa fluidité et le temps de réponse d'une extrémité de la connexion à l'autre.
Ainsi, dans le cadre d'une transmission média, la mémoire tampon servant à la construction des images est de taille variable, dépendant de la longueur des paquets et de la fluidité de rendu optimal calculée par l'application. Du côté de l'émetteur, un optimiseur de flux calcule périodiquement la qualité du trafic sur le réseau et adapte dynamiquement la taille des paquets afin d'éviter au maximum collisions et pertes.
En outre, le calcul de FEC étant la partie la plus longue du processus, l'optimisation de flux permet d'en varier la fréquence, créant ainsi une FEC-NACK adaptative qui répond au mieux aux problèmes rencontrés durant la transmission.

Transiter par des pare-feux ou le NAT

Transiter au travers d'un pare-feu
WebRTC peut être difficile à utiliser en entreprises dans la mesure où celles-ci ont souvent des politiques de sécurité en informatique incompatibles avec les besoins de l'API. En effet, WebRTC est basé sur des flux peer-to-peer entre navigateurs et ces flux sont très sensibles à la latence lorsqu'il s'agit de flux médias. En outre, les serveurs utilisés pour faire transiter les paquets peuvent être éloignés géographiquement des pairs qui communiquent ou avoir une bande passante trop faible pour permettre un transit correct des paquets.
Des approches existent déjà pour franchir un pare-feu : Le RTP symétrique est une implémentation de RTP basée sur UDP qui utilise les mêmes ports en entrée et en sortie, afin de simuler un flux bidirectionnel et éviter le blocage arbitraire de paquets;; Le protocole ICE, qui utilise des paquets de test pour déterminer les règles de filtrage du pare-feu et est aussi utilisé pour traverser un NAT.
Néanmoins les entreprises utilisent de plus en plus des SBC, des pare-feux de niveau application, utilisant un contrôle des flux de signaux et médias (ALG). Ces SBC posent des difficultés pour WebRTC dans la mesure où le flux de signaux n'est pas standardisé par l'API et l'implémentation est laissée libre. De plus, les SBC se placent comme intermédiaires dans la transmission du client vers le serveur, mais le protocole DTLS utilisé par WebRTC ne permet pas l'observation par un tiers de par son chiffrement. Enfin, les SBC utilisent les flux de signaux pour authentifier les flux de données, mais l'API WebRTC ne standardisant pas les flux de signaux, leur utilisation est impossible dans un but d'identification.
L'une des solutions pour venir à bout des difficultés posées par les SBC serait que les entreprises convertissent les flux entrants en sessions SIP, utilisent cette encapsulation pour traverser le SBC puis décapsulent le flux pour le transmettre à l'application. Cependant cette approche reprenant le principe de l'attaque de l'homme du milieu est rendue difficile par la variété des utilisations de WebRTC et par le chiffrement des flux de contrôle et de média de l'API.

Transiter au travers d'un NAT
Afin d'être utilisable si l'une des paires se situe derrière un NAT, WebRTC utilise le protocole ICE. Deux techniques principales sont utilisées pour traverser ce genre de difficultés. La première technique est souvent appelée Hole Punching (en): l'appareil à l'intérieur du NAT envoie un paquet STUN à un serveur en dehors du NAT. Le serveur répond en informant l'émetteur de l'adresse IP et du port apparent avec lequel le paquet a été envoyé, sur lequel les deux communiqueront. La seconde technique utilise un relais intermédiaire. Le protocole utilisé pour cela est Traversal Using Relays around NAT (en) : l'entreprise déploie un serveur TURN au sein de la zone démilitarisée (DMZ) avec lequel la paire interne communique et se charge de vérifier qu'il a les droits requis et de surveiller les flux médias qui passent par lui. Le serveur sert ainsi de point de relais aux paquets WebRTC qui transitent entre une paire et l'autre.

Intégration

Navigateurs web: Opera : une première intégration a été dévoilée en janvier 2012. La version stable comporte cette technologie;; Google Chrome : une intégration de la technologie est arrivée dans la branche de développement en janvier 2012, et dans la version stable numéro en juin 2012 (toutefois PeerConnection et MediaStream doivent être activés via la page chrome:--flags);; Mozilla Firefox : Mozilla a fait une démonstration en avril 2012. Le 8 janvier 2013, Firefox 18 a fait l'objet d'une implémentation préliminaire. La fondation a fait plusieurs démonstrations de cette fonction au sein de son navigateur. Mozilla a activé, par défaut, WebRTC dans Firefox 22 sorti le 25 juin 2013. La prise en charge de WebRTC dans Firefox mobile sur la plateforme Android est incluse depuis la version 24. Mozilla prévoit de prendre bientôt en charge TURN;; Internet Explorer: Microsoft a commencé l'intégration d'une API similaire, et Edge propose un support incomplet;; Ericsson a annoncé en octobre 2012, un premier navigateur compatible WebRTC pour téléphone mobile, appelé Bowser et développé pour iOS et Android;; En avril 2016 Safari (navigateur web) ne supporte pas le WebRTC mais Apple annonce travailler en ce sens.; En février 2017, Microsoft annonce le support de WebRTC sur les prochaines versions du navigateur Edge, à l'exception cependant des data channels.

Implémentations et démonstrations
Malgré sa relative nouveauté, la norme webRTC a déjà été implémentée dans le cadre de plusieurs projets dès 2011. Ainsi, en mai 2011, les laboratoires Ericsson ont proposé une première implémentation de l'API et en mai 2012, Doubango Telecom a proposé le premier client Sources ouvertes SIP HTML5 utilisant WebRTC. En septembre de la même année, un canvas logiciel à base de JavaScript pour faire tourner le protocole SIP baptisé JsSIP est lancé par Versatica, équipe déjà à l'origine du brouillon de travail sur les WebSockets.
Diverses applications sur l'internet utilisent les outils proposés par WebRTC. C'est le cas par exemple de tawk.com, appear.in, Talky.io, vroom.im ou encore Bistri.com, sites proposant des services de vidéoconférence. Dans la même mouvance, en novembre 2012, ToxBox lance OpenTok qui permet aux développeurs des visioconférences directement au sein de leurs sites Web ou de leurs applications IOS (Apple) et Android. Cette solution s'appuie sur WebRTC quand celui-ci existe au sein du navigateur ou sur Flash. De même, l'échange de données est offert par des sites tels que rtccopy, s'appuyant sur les DataChannel.
Malgré ces implémentations, les différents acteurs du web continuent de travailler sur la technologie. En février 2013, lors du Mobile World Congress Mozilla, Ericsson et ATT ont fait des démonstrations de WebRTC avec leurs produits. Le service de conversation de Google, Google Talk, pourrait lui aussi migrer vers WebRTC, le travail étant en cours.

Alternatives
En août 2012, Microsoft a présenté une proposition alternative appelée CU-RTC-WEB (Customizable, Ubiquitous Real Time Communication over the Web) au groupe WebRTC du W3C, une technologie qui aurait débuté en 2010 conjointement avec Skype (que Microsoft a racheté en 2011).
La proposition de Google s'appuie sur le codec VP8 non soumis à des redevances de brevets, tandis que la proposition de Microsoft utilise le standard ISO-CEI H.264, très répandu mais soumis aux redevances de nombreux brevets.
En 2016, Opera et Google Chrome ne supportent que le VP8, firefox et Bowser H.264 et VP8, et Edge partiellement H.264.

Voir aussi: Extensible Messaging and Presence Protocol; Jingle (protocole); Visiophonie; Voix sur IP.