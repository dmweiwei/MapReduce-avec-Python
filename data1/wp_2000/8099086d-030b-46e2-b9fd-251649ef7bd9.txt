En statistiques, un test d'hypothèse est une démarche consistant à évaluer une hypothèse statistique en fonction d'un jeu de données (échantillon).
Par exemple, ayant observé un certain nombre de tirages "pile ou face" produit par une pièce, on peut se demander si celle-ci est biaisée (c'est-à-dire possède une probabilité différente de 1-2 de tomber sur une face donnée). Dans cette situation, l'approche par test d'hypothèse consiste à supposer que la pièce est non biaisée (hypothèse nulle), et à calculer la probabilité d'observer des tirages au moins aussi extrêmes que celui effectivement observé (grâce à une loi binomiale). Si cette probabilité est faible (en pratique, inférieure à un seuil fixé, en général de 5 %), on rejette l'hypothèse nulle de l'équiprobabilité des faces de la pièce, et on décide qu'elle est biaisée. Toutefois, la probabilité qu'elle soit réellement biaisée n'est pas de 95 % (dans le cas général précité), mais dépend du risque de deuxième espèce.

Risque de première et deuxième espèce, puissance du test
Une notion fondamentale concernant les tests est la probabilité que l'on a de se tromper.
Il y a deux façons de se tromper lors d'un test statistique : rejeter l'hypothèse nulle alors qu'elle est vraie. On appelle ce risque le risque de première espèce et on note (-displaystyle -alpha) la probabilité de se tromper dans ce sens ;; retenir l'hypothèse nulle alors qu'elle est fausse. On appelle ce risque le risque de deuxième espèce et on note (-displaystyle -beta) la probabilité de se tromper dans ce sens.
On cherche à les minimiser mais en pratique, il faut trouver un compromis entre ces deux types d'erreur. La probabilité 1 (-displaystyle 1--beta) d'opter pour l'hypothèse de remplacement (H 1 (-displaystyle H-(1))) à raison s'appelle puissance du test.

Tests classiques et tests bayésiens
Pour les tests classiques qui constituèrent longtemps l'essentiel des tests statistiques, ces deux erreurs jouent un rôle asymétrique. On contrôle uniquement le risque de première espèce à un niveau (-displaystyle -alpha) (principe de Neyman) ; cela revient à considérer que le risque de rejeter l'hypothèse nulle alors que cette hypothèse est vraie est beaucoup plus coûteux que celui de la conserver à tort (ce dernier risque n'étant pas maîtrisé).
Les tests bayésiens, qui commencèrent à compléter les méthodes classiques dans les années 1970 à mesure que se répandaient les ordinateurs, pondèrent ces deux risques en représentant par une distribution la connaissance incertaine de cette probabilité. Si on cherche par exemple à tester le fait qu'un certain paramètre (-displaystyle -theta) vaut une certaine valeur 0 (-displaystyle -theta -(0)) cette probabilité a priori sera une distribution de (-displaystyle -theta) sur son domaine de plausibilité. Cette distribution a priori modélise l'incertitude admise sur sa valeur. Les tests correspondants utilisent en coulisses des calculs plus complexes, mais sans difficulté de mise en oeuvre supplémentaire quand ils sont effectués par des sous-programmes. Ils nécessitent de choisir une distribution a priori, répondant aux contraintes connues, parmi celles d'entropie maximale puis de l'affiner à mesure des observations en la mettant à jour par la règle de Bayes (voir Théorème de Cox-Jaynes). Leur mérite essentiel est de permettre la consolidation d'informations minuscules apportés par un grand nombre d'échantillons hétéroclites qui auraient chacun été considéré comme non significatif par les méthodes classiques. Cette consolidation permet d'obtenir des résultats utiles à partir d'observations très ténues. On l'utilise par exemple en cassage de codes, en analyse d'image et en reconnaissance vocale, ainsi qu'en deep learning.

Classification
D'ordinaire on range les tests dans deux catégories les tests paramétriques et les tests non paramétriques. Les premiers testent la valeur d'un certain paramètre. Ces tests sont généralement les tests les plus simples. Les tests non paramétriques quant à eux ne font pas intervenir de paramètre. C'est par exemple le cas des tests d'adéquation à une loi ou des tests du.
On peut également distinguer les tests d'homogénéité et les tests d'adéquations : dans le cas d'un test d'homogénéité, on veut comparer deux échantillons entre eux. L'hypothèse nulle H0 supposera l'homogénéité des deux échantillons. Par exemple on comparera deux moyennes ;; dans le cas d'un test d'adéquation (ou conformité), on veut déterminer si un échantillon suit une loi statistique connue. L'hypothèse nulle H0 supposera l'adéquation de l'échantillon à cette loi.

Déroulement d'un test
Pour le cas spécifique d'un test unilatéral, le test suit une succession d'étapes définies : 1) énoncé de l'hypothèse nulle H0 et de l'hypothèse de remplacement H1 ;; 2) calcul d'une variable de décision correspondant à une mesure de la distance entre les deux échantillons dans le cas de l'homogénéité, ou entre l'échantillon et la loi statistique dans le cas de l'adéquation (ou conformité). Plus cette distance sera grande et moins l'hypothèse nulle H0 sera probable. En règle générale, cette variable de décision s'appuie sur une statistique qui se calcule à partir des observations. Par exemple, la variable de décision pour un test unilatéral correspond à rejeter l'hypothèse nulle si la statistique dépasse une certaine valeur fixée en fonction du risque de première espèce ;; 3) calcul de la probabilité, en supposant que H0 est vraie, d'obtenir une valeur de la variable de décision au moins aussi grande que la valeur de la statistique que l'on a obtenue avec notre échantillon. Cette probabilité est appelée la valeur p (p-value) ;; 4) conclusion du test, en fonction d'un risque seuil seuil, en dessous duquel on est prêt à rejeter H0. Souvent, un risque de 5 % est considéré comme acceptable (c'est-à-dire que dans 5 % des cas quand H0 est vraie, l'expérimentateur se trompera et la rejettera). Mais le choix du seuil à employer dépendra de la certitude désirée et de la vraisemblance des autres choix ;; 5) si la valeur p est plus petite que (-displaystyle -alpha), on rejette l'hypothèse nulle ;; 6) si la valeur p est plus grande que (-displaystyle -alpha), on peut utiliser la puissance 1 (-displaystyle 1--beta), si elle est grande, on accepte H0 ; sinon le test est non concluant, ce qui revient à dire que l'on ne peut rien affirmer.
La probabilité pour que H0 soit acceptée alors qu'elle est fausse est , le risque de deuxième espèce. C'est le risque de ne pas rejeter H0 quand on devrait la rejeter. Sa valeur dépend du contexte, et peut être très difficilement évaluable (voire impossible à évaluer) : c'est pourquoi le risque est principalement utilisé comme critère de décision, on n'accepte que très rarement H0 et la plupart du temps on conclut à un test non concluant si on ne rejette pas H0.

Tests classiques
Il existe de nombreux tests statistiques classiques parmi lesquels on peut citer : le test de Student, qui sert à la comparaison d'une moyenne observée avec une valeur "attendue" pour un échantillon distribué selon une loi normale ;; le test de Fisher, aussi appelé test de Fisher-Snédécor, qui sert à la comparaison de deux variances observées ;; l'analyse de la variance ou Anova, permet de comparer entre elles plusieurs moyennes observées (pour les groupes étudiés), selon un plan expérimental prédéterminé. Elle se fonde sur une décomposition de la variance en une partie "explicable" (variance inter-groupes) et une partie "erreur" (variance globale intragroupe - ou variance résiduelle), supposée distribuée selon une loi normale. Ce test est particulièrement utilisé en sciences humaines, sciences sociales, sciences cognitives, en médecine et en biologie ;; le test du , également appelé test du 2 (-displaystyle -chi (2)) de Pearson, qui sert notamment à la comparaison d'un couple d'effectifs observés, ou à la comparaison globale de plusieurs couples d'effectifs observés, et plus généralement à la comparaison de deux distributions observées ;; le test de Kolmogorov-Smirnov, qui comme le test du 2 (-displaystyle -chi (2)) constitue un test d'adéquation entre des échantillons observés et une distribution de probabilité. Il compare la fonction de répartition observée et la fonction de répartition attendue. Il est particulièrement utilisé pour les variables aléatoires continues.
En inférence bayésienne, on utilise le psi-test (mesure de distance dans l'espace des possibles) dont on démontre que le test du 2 (-displaystyle -chi (2)) représente une excellente approximation asymptotique lorsqu'il existe un grand nombre d'observations.

Voir aussi

Articles connexes: Plan d'expérience; Test (statistique); Test de Jarque-Bera; Statistique mathématique.