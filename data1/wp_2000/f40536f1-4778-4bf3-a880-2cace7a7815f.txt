La sémantique est une branche de la linguistique qui étudie les signifiés, ce dont on parle, ce que l'on veut énoncer. Sa branche symétrique, la syntaxe, concerne pour sa part le signifiant, sa forme, sa langue, sa graphie, sa grammaire, etc ; c'est la forme de l'énoncé.
En particulier, la sémantique possède plusieurs objets d'étude : la signification des mots composés ;; les rapports de sens entre les mots (relations d'homonymie, de synonymie, d'antonymie, de polysémie, d'hyperonymie, d'hyponymie, etc.) ;; la distribution des actants au sein d'un énoncé ;; les conditions de vérité d'un énoncé ;; l'analyse critique du discours ;; la pragmatique, en tant qu'elle est considérée comme une branche de la sémantique.
Le terme de sémantique est utilisé en opposition à celui de syntaxe dans l'étude des langages de programmation en informatique, pour laquelle elle a été développée de manière formelle (voir sémantique des langages de programmation). Il y a entre la sémantique et la syntaxe le même rapport qu'entre le fond et la forme. George Lakoff a étudié la sémantique influençant la syntaxe.

Étymologie
Le mot sémantique est dérivé du grec (sêmantikos), "signifié" lui-même formé à partir de (sêmainô), "signifier, indiquer" ou (sêma), "signe, marque". Il a été repris à la fin du XIXe siècle par le linguiste français Michel Bréal, auteur du premier traité de sémantique.

Différence entre l'analyse sémantique et l'analyse syntaxique
L'analyse syntaxique aussi bien que l'analyse sémantique en linguistique a pour finalité de caractériser l'énoncé dans son ensemble principalement par la détermination des structures de l'énoncé. Dans les deux cas, la détermination des structures sera basée sur une caractérisation de ses éléments de base, les mots, et leurs propres constituants, mais de façon différente selon ces deux approches.
L'analyse syntaxique va s'occuper des syntagmes et elle s'en occupera par rapport à une phrase. On ne peut pas faire d'analyse syntaxique du mot "petites" par exemple s'il n'est pas inclus dans une phrase, en relation avec d'autres mots compléments ou chefs de groupe.
L'analyse syntaxique peut ainsi être identifiée comme une analyse des structures fonctionnelles pouvant être obtenues au moyen de l'exercice des règles de la grammaire.
L'analyse sémantique de son côté s'intéresse à ces structures en observant les mécanismes propres à la construction du sens. À savoir : un sème est la plus petite unité de sens.
La sémantique peut s'intéresser à un mot pour le mot. On analysera ainsi le mot "petites" :
PETIT (Adj. qui n'est pas grand) + E (marque de féminin) + S (marque de pluriel) (PETIT - la base ou le radical du mot (signe lexical), E + S - sont des signes grammaticaux).
Pour le mot "petites" nous avons donc trois sèmes.
À partir de ce même mot, d'autres analyses sont possibles sans forcément mettre en lumière un énoncé entier. (cf introduction)
La distinction entre analyse syntaxique et analyse sémantique qui est établie ici correspond à l'approche la plus répandue en linguistique contemporaine, celle qui hérite du structuralisme introduit par Ferdinand de Saussure. On rencontrera les termes d'analyse structurale ou analyse componentielle employés comme équivalents pour signifier au plus directement l'approche utilisée pour effectuer l'analyse sémantique selon cette théorie. La structure est perçue comme directement sous-jacente à la phrase, cette dernière étant une structure ainsi qu'il est mis en évidence par la syntaxe ou la grammaire, et le mot étant considéré comme associé à ses traits sémantiques. D'autres approches, comme principalement la grammaire de dépendance de Lucien Tesnière, antérieure au structuralisme, réservent la qualification de structure au niveau syntaxique. Pour Tesnière, le niveau syntaxique est appelé plan structural tandis que le plan sémantique est considéré comme relevant de la psychologie, et également de la logique.

Applications à l'exploration de données
Les méthodes d'exploration de données permettent de dégager du sens d'un ensemble de données d'allure a priori disparates (voir aussi intelligence artificielle) et donc créent de la sémantique. La sémantique dégagée prend généralement trois formes (traduction par des signifiants formels) issues de l'intelligence artificielle : Le tableau ;; Le graphe (réseau maillé d'objets, de concepts, etc.) ;; L'arbre (cas particulier de graphe nécessitant une théorie et une exploitation spécifiques).
Ce sont des signifiants, au sens où ils représentent les connaissances. De telles structures sont ensuite annotées dans les données de départ, chaque donnée portant alors la marque de son appartenance à une branche de l'arbre, une case du tableau, etc. L'analyse reprend alors à un niveau de compréhension plus complexe.

La découverte des connaissances dans les bases de données
Toutefois, la machine ne manipulant que des signifiants, il est impératif que la démarche de forage de données fasse intervenir un expert humain du domaine. Celui-ci va restituer la sémantique extraite et lui donner du sens, de la valeur. Trois critères sont exhibés à cette fin : Est-ce connu ; Est-ce explicable ; Est-ce utile.
L'idéal est d'avoir un triplet NON-OUI-OUI.
Un tel projet est appelé "découverte des connaissances dans les bases de données", en anglais KDD, Knowledge Discovery in Databases.
Finalement, la sémantique extraite tient le rôle d'une cartographie de l'information, elle permet de situer les informations les unes par rapport aux autres. Ce rôle "cartographique" permet de stocker l'information, de la ranger et plus tard de la retrouver. Tout modèle, jeu de catégories, topique freudienne est alors de facto une cartographie de l'information, c'est-à-dire un contexte formalisé.
Ce sont en fait des données sur les données, des métadonnées. Des architectures informatiques spécifiques permettent de gérer ces métadonnées, on parle de client ou de serveur de métadonnées. Un système connu est le Dublin Core Metadata Initiative (DCMI). (voir Dublin Core)
Le Web sémantique est un projet du même type que DCMI, visant à créer, gérer et exploiter des métadonnées systématiques pour chaque page web. Ainsi le contenu de chaque page web étant explicité vers des signifiants, la machine serait capable de raisonner sur la pertinence du contenu et non plus sur des statistiques lexicales. Cela peut avoir des conséquences remarquables sur les technologies de recherche d'informations, ainsi que l'allure et le fonctionnement des moteurs de recherche.

Cas particulier de la fouille textuelle
La fouille textuelle consiste à transformer un objet "texte" en un objet "tableau", "arbre" ou "graphe" à l'aide de traitements sémantiques ou syntaxiques puis à appliquer des techniques de fouille textuelle sur cet objet formalisé. Les résultats attendus sont généralement : Le résumé automatique ;; L'indexation automatique ;; La génération d'index de livre (vedettes et sous-vedettes) ;; L'extraction et la cartographie de concepts ;; La classification automatique ;; Le rapprochement entre textes.
L'approche sémantique a une littérature plus féconde que l'approche syntaxique : même si cette dernière a des résultats supérieurs, les ressources de calcul demandées font souvent pencher la balance en faveur de l'analyse sémantique.
L'analyse sémantique transforme un ensemble de textes en une matrice lexicale : En ligne, chaque texte ;; En colonne, chaque mot-clé apparaissant au moins une fois dans l'un des textes ;; Dans les cases, un ratio numérique mesurant à la fois la fréquence d'apparition d'un mot-clé dans un texte et la fréquence d'apparition du mot-clé dans le corpus.

Cas particulier des ontologies
Le terme "ontologie" a une signification philosophique, mais en gestion des connaissances, il représente la forme probablement la plus évoluée de représentation sémantique des connaissances. Il s'agit d'une sorte de "superthésaurus" destiné à indexer toutes les productions documentaires, stockées, entrantes ou sortantes dans un groupe social donné, typiquement une entreprise. Ainsi, un courrier électronique, un ouvrage de référence, un document de travail partageant les mêmes thèmes seront automatiquement mis en lien, donc mis en contexte, dégageant ainsi des connaissances sémantiques. La structuration d'une ontologie est pratiquement un métier en soi, à l'instar de la conception et de la maintenance des thésaurus de bibliothèques. La construction est toujours collective et par agglomération de domaines de compétence.
L'articulation de base d'une ontologie est la suivante : C'est un arbre sémantique ;; Chaque mot-clé est affublé de lexicons : synonymes, homonymes, hyperonymes, homophonies traduction dans d'autres langues, etc. Ce micro-réseau autour d'un mot-clé est appelé concept ou classe ;; Chaque concept est à considérer comme une catégorie de thésaurus, donc avec des catégories plus larges ou plus étroites. Ce lien d'appartenance est interprété comme un lien logique ;; Chaque concept peut avoir des instances, soit des éléments appartenant à cette catégorie.
Exemple : OISEAU AIGLE (aigle royal). La machine peut alors inférer que l'aigle royal est un oiseau. Les liens entre concepts peuvent être beaucoup plus complexes que la simple subordination, sortant ainsi du cadre du thésaurus. Si les concepts sont assimilables à des groupes nominaux, les liens sont assimilables à des groupes verbaux : on regroupe ces liens en catégories de liens. La structure du réseau est parfois appelée topic map.
En pratique, on pourrait ainsi traduire automatiquement un manuel d'histoire en ontologie, en considérant cinq types de concepts (date, lieu, événement, personne physique, personne morale) et une trentaine de catégories de liens verbaux. En plus des lexicons, les instances peuvent pointer vers des ressources ou URI. Généralement, ce sont les documents que l'on cherche à indexer.
Pour la machine, raisonner sur les connaissances ainsi représentées revient à "se promener" dans le réseau de concepts, à la manière d'un réseau routier. Il existe des algorithmes spécifiques, par exemple les chercheurs de chemins (Pathfinder), qui cherchent le plus court chemin d'un concept à l'autre en respectant un critère d'économie : "plus petit nombre de concepts", "plus grand nombre de langues", "plus grand nombre de synonymes", etc. Les résultats peuvent être spectaculaires, surtout si l'on garde présent à l'esprit que le point de départ et le point d'arrivée ne sont pas les concepts, mais bien les URI indexés (documents de l'entreprise).

Voir aussi

Articles connexes: Analyse sémantique, Combinatoire sémantique, Sème, Classe sémantique, Trait sémantique; Dénotation et connotation, sens et dénotation; sémantique musicale, sémantique générale; sémiotique, sémiotique visuelle; signification Signification (philosophie) signifiance (dimension syntaxique du sens); philosophie du langage; représentation (grammaire); web sémantique : une extension du web qui via une formalisation du sens des contenus (description du sens des pages dans un langage compréhensible par une machine) permet par exemple de les rendre accessibles à des processus automatisés,; Sémantique générative; Lexicologie, Lexicographie, Dictionnaire; Natural Semantic Metalanguage (NSM) : à la recherche des primitives sémantiques avec Anna Wierzbicka; Lexical markup framework: LMF, travaux de normalisation ISO des lexiques du TAL; Théorie Sens-Texte (Igor Mel'čuk).

Listes: Liste de linguistes; Roger Schank, Robert Abelson, Richard Montague, Ghil'ad Zuckermann, François Rastier, Eugen Coșeriu, Juri Apresjan, Igor Mel'čuk,.