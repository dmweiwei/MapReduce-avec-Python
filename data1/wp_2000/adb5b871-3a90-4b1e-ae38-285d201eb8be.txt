En statistique, une donnée aberrante est une valeur ou une observation qui est "distante" des autres observations effectuées sur le même phénomène, c'est-à-dire qu'elle contraste grandement avec les valeurs "normalement" mesurées. Une donnée aberrante peut être due à la variabilité inhérente au phénomène observé ou bien elle peut aussi indiquer une erreur expérimentale. Les dernières sont parfois exclues de la série de données.
Les données aberrantes peuvent apparaitre par hasard dans n'importe quelle distribution, mais elles indiquent souvent soit une erreur de mesure soit que la population est distribuée suivant une loi de probabilité à queue lourde. Dans le premier cas, il convient de se débarrasser de ces valeurs ou bien d'utiliser des indicateurs statistiques plus robustes face aux données aberrantes tandis que dans le second cas elles indiquent que la distribution est fortement asymétrique et qu'il faut donc se montrer très prudent dans l'utilisation d'outils ou de raisonnement conçus pour une distribution normale. Une cause fréquente de données aberrantes est le mélange de deux distributions, qui peuvent être issues de 2 sous-populations bien distinctes, ou qui peuvent indiquer "mesure correcte" contre "erreur de mesure": ce phénomène peut être modélisé au travers d'un modèle de mélange.
Dans de plus grandes séries de données, quelques valeurs peuvent être éloignées de façon raisonnable de la moyenne. Cela peut être dû à une erreur systématique aussi appelée biais qui peut être inhérent au modèle utilisé pour décrire la distribution du phénomène, ou il peut s'agir de quelques valeurs qui sont loin du centre des données. Les données aberrantes peuvent également indiquer une donnée fausse, des calculs erronés ou bien les limites d'un modèle statistique. Cependant, dans de grands échantillons, un petit nombre de données aberrantes est attendu (qui n'est dû à aucune condition anormale).
Les données aberrantes, regroupant les valeurs les plus extrêmes, peuvent inclure la valeur maximale ou la valeur minimale, ou les deux: cela dépend si ces valeurs sont extrêmement élevées ou faibles. Cependant, les valeurs maximum et minimum ne sont pas toujours des données aberrantes car elles peuvent ne pas être trop éloignées des autres valeurs.
Une interprétation statistique naïve d'une série de données contenant des données aberrantes peut être trompeuse et induire en erreur. Par exemple, si une personne décide de calculer la température moyenne de 10 objets dans une pièce, et que 9 d'entre eux ont une température située entre 20 et 25 degrés Celsius mais que le dernier est un four en marche à 175 C, la médiane de la série sera située entre 20 et 25 C mais la température moyenne sera entre 35,5 et 40 C. Dans ce cas, la médiane est un meilleur indicateur de la température des objets que la moyenne. Il est incorrect de penser que la moyenne et la médiane sont des indicateurs équivalents. Comme illustré dans cet exemple, le caractère aberrant de certaines données peut révéler leur appartenance à une population différente du reste des valeurs de la série.
Les indicateurs ou estimateurs capables de composer avec les données aberrantes sont dits robustes: la médiane est un indicateur robuste tandis que la moyenne n'en est pas un.

Évènement et causes
Pour une distribution normale, 68,27% des valeurs sont comprises dans l'intervalle (-;+), 95,45% sont comprises dans l'intervalle (-2;+2) et 99,73% sont comprises dans l'intervalle (-3;+3).
Dans le cas de données normalement distribuées, la règle des trois sigmas indique qu'à peu près 1 observation sur 22 aura un écart avec la moyenne égal ou supérieur à 2 fois l'écart-type et qu'environ 1 observation sur 370 aura un écart avec la moyenne égal ou supérieur à 3 fois l'écart-type. Ainsi, cette loi empirique nous permet de déterminer si le nombre de données aberrantes trouvées est normal ou s'il faut rechercher une autre cause que celle du hasard statistique. Par exemple, dans un échantillon de 1000 valeurs, le fait de trouver 5 données aberrantes qui diffèrent de la moyenne d'un écart supérieur à 3 fois l'écart-type est "normal" - voir la distribution de Poisson - et ne suggère aucune anomalie dans la série de valeurs. Cependant, si la taille de l'échantillon est de 100 valeurs, le fait de trouver seulement 3 données aberrantes suffit à montrer qu'il y a une raison autre que le simple hasard (valeurs issues d'une autre population ou biais du modèle...) car cela représente plus de 11 fois le nombre attendu avec la règle des trois sigmas.
En général, si la nature de la distribution de la population est connue a priori, il est possible de tester si le nombre de données aberrantes diffère significativement de ce qui est attendu: pour un seuil donné (donc les valeurs ont une probabilité p de se situer dans l'intervalle (-seuil;seuil)) d'une distribution donnée, le nombre de données aberrantes suivra une distribution binomiale de paramètre p, qui peut généralement être approximée par une distribution de Poisson de paramètre - pn. Ainsi, si l'on prend une distribution normale avec un seuil à 3 écart-types de la moyenne, p est d'environ 0,3%, et donc pour 1000 valeurs, on peut approximer le nombre de valeurs dont l'écart est supérieur au seuil (donc 3) par une distribution de Poisson avec - 3.

Causes
Les données aberrantes peuvent avoir de multiples causes. Un appareil de mesure peut avoir un défaut de fonctionnement passager. Il peut y avoir une erreur dans la transmission ou dans la retranscription des données. Il peut y avoir eu un changement dans les procédures, un comportement frauduleux ou une erreur humaine. Un échantillon peut aussi avoir été "contaminé" par des individus n'appartenant pas à la population étudiée. Attention ! une donnée peut sembler aberrante alors qu'elle n'est qu'extrême et compatible avec les variations naturelles d'une population. Son caractère apparemment aberrant peut aussi révéler la mauvaise adéquation du modèle statistique utilisé pour interpréter les données, appelant à une enquête plus approfondie par le chercheur. L'aspect pathologique des données aberrantes d'une certaine forme (le mot pathologique est utilisé dans le sens où, quelles que soient les conditions de l'expérience, il y aura toujours des données extrêmes dues au hasard), qui apparaît dans une variété de séries de valeurs, peut indiquer que le mécanisme causal diffère entre les données aux extrémités de la série (King effect).

Identifier des données aberrantes
Il n'y a pas de définition mathématique claire sur ce qu'est une donnée aberrante. Déterminer si une observation est ou n'est pas une donnée aberrante est un exercice très subjectif. Il existe cependant des méthodes variées pour la détection des données aberrantes. Quelques-unes sont graphiques telles que la technique de la droite de Henry, d'autres sont basées sur des modèles, la technique des boites à moustaches est un hybride.

Comparaison des écarts à l'écart-type
Les méthodes basées sur des modèles sont utilisées pour l'identification des données aberrantes lorsque les données sont issues d'une distribution normale. Ces méthodes identifient les observations qui sont considérées comme "peu probables" sur la base de la moyenne et de l'écart-type. Test de Chauvenet; Test de Grubbs; MMS, test d'identification des données aberrantes en régression linéaire.; Test de Peirce (en): "Il est proposé de déterminer dans une série de m (-displaystyle m) observations le seuil à partir duquel toutes les observations peuvent être rejetées, à condition qu'il y ait un nombre n (-displaystyle n) d'observations rejetées. On résout ce problème en considérant que les observations doivent être rejetées lorsque la probabilité d'erreur obtenue en les conservant est inférieure à la probabilité d'erreur obtenue en les rejetant multipliée par la probabilité de faire autant, et pas plus, d'observations anormales" (phrase citée dans l'éditorial à la page 516 sur Peirce (édition de 1982) du A Manual of Astronomy 2:558 de Chauvenet). Test Q de Dixon; Les conventions E178 énoncées par l'ASTM International pour traiter les données aberrantes.; La distance de Mahalanobis et la technique de l'influence sont souvent utilisées pour détecter les données aberrantes, particulièrement lors du développement de modèle de régression linéaire.

Autres appréciations de la variabilité
D'autres méthodes existent également et sont basées sur des mesures telles que l'écart interquartile. Par exemple, si Q 1 (-displaystyle Q-(1)) et Q 3 (-displaystyle Q-(3)) sont respectivement le premier quartile et le troisième quartile, alors on peut définir une donnée aberrante comme étant toute valeur située à l'extérieur de l'intervalle: (Q 1 k (Q 3 Q 1) , Q 3 + k (Q 3 Q 1)) (-displaystyle (-big Q-(1)-k(Q-(3)-Q-(1)),Q-(3)+k(Q-(3)-Q-(1))(-big))).
avec k (-displaystyle k) une constante positive.
Dans la tâche d'exploration de données consistant en la détection d'anomalies, d'autres approches sont basées sur des distances ou sur la densité, et un grand nombre d'entre elles utilisent la méthode des k plus proches voisins pour identifier une valeur comme étant une donnée aberrante ou non.

Test Tau de Thompson modifié
Le test Tau de Thompson modifié est une méthode utilisée pour déterminer s'il existe des données aberrantes dans une série de valeurs. La force de cette méthode réside dans le fait qu'elle prend en compte l'écart-type et la moyenne de la série et fournit un seuil de rejet déterminée statistiquement ; cela offre donc une méthode objective pour déterminer si une valeur est une donnée aberrante.
Déroulement du test: Premièrement, on détermine la moyenne de la série. Ensuite, on détermine l'écart à la moyenne de chaque valeur. Puis, un seuil de rejet est déterminé en utilisant la formule suivante : S e u i l - t - 2 (n 1) n n 2 + t - 2 2 (-displaystyle Seuil(-)(-frac ((t-(-alpha -2))(-left(n-1-right)))((-sqrt (n))(-sqrt (n-2+(t-(-alpha -2)(2))))))); où t - 2 (-displaystyle (t-(-alpha -2))) est la valeur critique provenant de la table de la Loi de Student, n (-displaystyle n) est l'effectif de l'échantillon et s (-displaystyle s) est l'écart-type de l'échantillon.
Pour déterminer si une valeur est une donnée aberrante, calculer - X x s (-displaystyle (-frac (X-(-bar (x)))(s))) : si Seuil, la valeur est une donnée aberrante ; si Seuil, la valeur n'est pas une donnée aberrante.
Le test Tau de Thompson modifié est utilisé pour trouver une donnée aberrante à la fois (la plus grande valeur de est changée si c'est une donnée aberrante). En ce sens, si une valeur est calculée comme étant une valeur aberrante, elle est enlevée de la série de valeurs et le test est appliqué à nouveau avec une nouvelle moyenne et un nouveau seuil de rejet. Ce procédé est renouvelé jusqu'à ce qu'il n'y ait plus de données aberrantes dans la série.

Autres approches
Certains travaux ont également tenté de décrire les données aberrantes pour des série de valeur nominales. Par exemple, dans un contexte d'une série d'exemples (ou de cas) dans une série de valeurs, on crée un indicateur nommé la solidité des cas qui mesure la probabilité qu'un cas soit mal classé (1 p (y x) (-displaystyle 1-p(yx)) où y (-displaystyle y) est le terme assigné à la classe et x (-displaystyle x) représente la valeur attribuée à un cas dans la série d'exemples t (-displaystyle t)). Idéalement, la solidité des cas sera calculée en faisant la somme sur la série de toutes les hypothèses H (-displaystyle H) possibles: I H (x , y) - H (1 p (y , x , h)) p (h t) - H p (h t) p (y , x , h) p (h t) - 1 H p (y , x , h) p (h t). (-displaystyle (-begin(aligned)IH(-langle x,y-rangle)--sum -(H)(1-p(y,x,h))p(ht)----sum -(H)p(ht)-p(y,x,h)p(ht)---1--sum -(H)p(y,x,h)p(ht).-end(aligned))).
De manière pratique, cette formule est irréalisable car H (-displaystyle H) est potentiellement infinie et calculer p (h t) (-displaystyle p(ht)) est impossible pour bon nombre d'algorithmes. Ainsi, la robustesse des cas peut être approximée en utilisant un sous-ensemble L H (-displaystyle L-subset H): I H L (x , y) - 1 1 L j - 1 L p (y x , g j (t ,) (-displaystyle IH-(L)(-langle x,y-rangle)-1-(-frac (1)(L))-sum -(j-1)(L)p(yx,g-(j)(t,-alpha)).
où g j (t ,) (-displaystyle g-(j)(t,-alpha)) est l'hypothèse induite par l'algorithme d'apprentissage g j (-displaystyle g-(j)) formé sur la série de valeurs t (-displaystyle t) avec des hyperparamètres (-displaystyle -alpha). La solidité des cas fournit une valeur continue pour déterminer si un cas est une donnée aberrante.

Travailler avec des données aberrantes
Le choix de composer ou non avec une donnée aberrante dépend de la cause de cette dernière.

Conservation de la donnée aberrante
Même quand un modèle de distribution normale est approprié pour analyser des valeurs, des données aberrantes sont attendues pour de grands échantillons et elle ne doivent pas être automatiquement exclues. En effet, il est préférable d'utiliser des algorithmes robustes face aux données aberrantes plutôt que des modèles qui écartent systématiquement ces valeurs.

Exclusion de la donnée aberrante
La suppression des données aberrantes est une pratique controversée désapprouvée par de nombreux scientifiques et professeurs; tant qu'il n'y aura pas de critères mathématiques permettant d'offrir une méthode objective et quantitative pour le rejet de valeurs, il sera impossible de rendre la pratique de suppression des données aberrantes scientifiquement et méthodologiquement plus acceptable. En particulier pour les petits échantillons et si la nature de la distribution est inconnue et ne peut être approximée par une loi normale. Le rejet de données aberrantes est plus acceptable si le modèle sous-jacent au phénomène a été mesuré et que la distribution des erreurs de mesures est connue précisément. Une donnée aberrante résultant d'un instrument dont on sait qu'il fait des erreurs peut être exclue mais il est préférable de vérifier avant si l'instrument fait réellement des erreurs.
Les deux approches les plus utilisées pour exclure les données aberrantes sont la méthode de césure (ou tronquage) et de Winsorising. La césure élimine les données aberrantes alors que le Winsorising remplace les données aberrantes par les valeurs "non suspectes" les plus proches. L'exclusion peut aussi être une conséquence du processus de mesure. En effet, si lors d'une expérience un instrument n'est pas capable de mesurer de telles valeurs extrêmes, il en résulte des valeurs censurées.
Dans des problèmes de régression, une autre approche consiste à exclure uniquement les valeurs qui présentent un haut degré d'influence sur les coefficients estimés, notamment en utilisant une mesure telle que la distance de Cook.
Si une valeur (ou donnée) est exclue de l'analyse des données, cela doit être clairement indiqué sur tous les rapports émanant de l'analyse.

Distributions non-normales
Il faut également considérer que les valeurs de la série étudiée ne suivent pas une distribution normale et qu'elles peuvent avoir des "queues épaisses". Par exemple, lors de l'échantillonnage à partir d'une distribution de Cauchy, la variance augmente avec la taille de l'échantillon, la moyenne de l'échantillon est biaisée et ne converge pas lorsque la taille de l'échantillon augmente. De plus, les données aberrantes sont attendues à un taux beaucoup plus important que pour une distribution normale. Même une légère différence dans l'épaisseur de la queue peut créer une importante différence dans le nombre de valeurs extrêmes attendues.

Les incertitudes d'appartenance à l'ensemble
intersection q-relâchée de 6 ensembles pour q- 2 (rouge), q- 3 (vert), q- 4 (bleu) et q- 5 (jaune).
Une approche d'appartenance à l'ensemble considère que l'incertitude correspondant à la mesure d'une variable aléatoire x est représentée par un ensemble Xi (au lieu d'une fonction de densité de probabilité). Si aucune donnée aberrante n'apparaît, x appartient à l'intersection de tous les Xi. Si une donnée aberrante apparaît, cette intersection est vide et nous relâchons un petit nombre de Xi (aussi petit que possible) afin d'éviter toute incohérence. Cela peut être fait en utilisant la notion d'intersection q-relâchée. Comme illustré par la figure, l'intersection q-relâchée correspond à l'ensemble de tous les x qui appartiennent à tous les ensembles Xi exceptés q d'entre eux. Les ensembles Xi qui ne coupent pas l'intersection q-relâchée peuvent être soupçonnés de rassembler des données aberrantes.

Autres modèles
Dans le cas où la cause des données aberrantes est connue, il peut être possible d'incorporer cet effet dans le modèle. Par exemple en utilisant un modèle hiérarchique de Bayes ou un modèle de mélange.

Voir aussi

Articles connexes: Anomalie des séries de temps; Régression robuste; Résidu studentisé; Transformation de données (statistiques); Facteur local de données aberrantes.