Un microprocesseur multi-coeur (multi-core en anglais) est un processeur possédant plusieurs coeurs physiques fonctionnant simultanément. Il se distingue d'architectures plus anciennes (360-91) où un processeur unique commandait plusieurs circuits de calcul simultanés.
Un coeur physique est un ensemble de circuits capables d'exécuter des programmes de façon autonome. Toutes les fonctionnalités nécessaires à l'exécution d'un programme sont présentes dans ces coeurs : compteur ordinal, registres, unités de calcul, etc. Des caches sont définis pour chaque processeur ou partagés entre eux.

Histoire

Origines
Le terme "multi-coeur" est employé pour décrire un processeur composé d'au moins deux coeurs (ou unités de calcul) gravés au sein de la même puce.
On doit à IBM le premier processeur multi-coeur à avoir été commercialisé : il s'agit du POWER4, en 2001. En 2003, Sun lance l'UltraSPARC IV composé de 2 coeurs UltraSPARC III. En 2004, HP lance le PA-8800 composé de 2 coeurs PA-8700.
Les premiers exemplaires de processeurs multi-coeurs d'Intel et d'AMD sont arrivés sur le marché des ordinateurs personnels en 2005. Il s'agissait de coeurs homogènes, c'est-à-dire identiques. Le cas de coeurs différents et spécialisés dans des domaines bien précis (audio, affichage, calcul pur, etc) a été exploité pour le processeur Cell conçu par IBM, Sony et Toshiba. Ce type d'architecture permet d'augmenter la puissance de calcul sans augmenter la fréquence d'horloge, et donc de réduire la quantité de chaleur dissipée par effet Joule (comme pour les systèmes multiprocesseur).
Les premières puces double coeur basées sur l'architecture x86 sont apparues en 2005 sur le marché des serveurs (Opterons d'AMD). Elles sont apparues parce qu'en pratique la course au GHz devenait onéreuse et compliquée. La génération de processeurs de cette époque ne possédait qu'un seul coeur et avait une consommation qui pouvait dépasser largement les 100 W (notamment sur les processeurs Intel Pentium 4). Elle devait donc faire face à de graves problèmes de refroidissement des circuits. La solution qui a semblé la plus évidente a été de privilégier non plus la fréquence, mais d'accroître la puissance grâce à une architecture parallèle, de façon à pouvoir augmenter le nombre d'opérations exécutées simultanément en un cycle d'horloge.

Évolution de la technologie
Depuis le lancement du premier ordinateur sur le marché, les demandes en capacité de calcul sont devenues de plus en plus importantes. Le multitraitement symétrique (SMP) a longtemps été utilisé pour améliorer les performances et l'efficacité informatiques en répartissant les charges sur plusieurs processeurs. Le SMP est particulièrement efficace dans les environnements multiprocessus où plusieurs tâches (processus) doivent être gérées simultanément.
Avec l'évolution des demandes de performances applicatives, les concepteurs de processeurs sont confrontés à un problème : L'augmentation des capacités informatiques est tributaire de la puissance, et le fait d'augmenter la puissance nécessite de gérer aussi les niveaux de dissipation. À cela s'ajoutent les demandes des industriels qui souhaitent des ordinateurs moins encombrants, à savoir plus de serveurs par baie, des ordinateurs portables plus fins et plus légers, et un encombrement réduit pour les systèmes de bureau. Le traitement multicoeur contribue à relever ces défis. Cette évolution technologique augmente les performances et la productivité dans des ordinateurs de plus petite taille capables d'exécuter simultanément plusieurs applications complexes et de réaliser davantage de tâches en moins de temps.
Un langage comme Go permet de concevoir des programmes qui fonctionneront sans réécriture sur un nombre quelconque de coeurs.

Processeurs multicoeurs existants
Il existe actuellement plusieurs architectures de processeurs multi-coeurs. Outre les modèles d'Intel et AMD déjà cités, Sun Microsystems a développé sa gamme Niagara et Niagara II ; IBM a développé sa gamme de PowerPC et sa ligne CellBE, commercialisée par IBM sous forme de serveur lame, par Mercury sous forme de châssis renforcé. Le tout premier processeur double coeur pour smartphone lancé par Nvidia fut le Tegra 2 lancé en 2011.
L'industrie cherche dans le même temps à multiplier le nombre de coeurs présents sur un processeur, par exemple Intel dans son projet Tera-Scale.

Partage des caches
Caches dédiés.
Tout processeur actuel contient des mémoires caches, qui rendent les accès à la mémoire plus rapides. Sur les processeurs multicoeurs, l'organisation de ces mémoires caches est adaptée à la présence de plusieurs coeurs. Deux grandes organisations de base sont utilisées : celle à base de caches dédiés à chaque coeur, et celle à base de caches partagés.
Dans le cas des caches dédiés, chaque coeur possède son propre cache, que lui seul peut utiliser. On trouve donc un cache pour chaque coeur.
Caches partagés.
Avec les caches partagés, la mémoire cache est partagée entre tous les processeurs, qui peuvent y accéder de façon concurrente.

Avantages et inconvénients des caches dédiés
L'organisation à base de caches dédiés a quelques avantages : Un programme qui s'exécute sur un coeur ne va pas polluer le cache d'un autre processeur : deux programmes exécutés sur des coeurs différents n'interfèrent pas ;; Le temps d'accès à un cache dédié est souvent plus faible que celle d'un cache partagé. Il faut dire que les caches dédiés sont souvent d'une taille assez faible comparé à un gros cache partagé, conçu pour répondre aux besoins de plusieurs coeurs.

Avantages et inconvénients des caches partagés
Mais l'organisation à base de caches partagés a aussi des avantages : Deux programmes peuvent se partager le cache dynamiquement : ils peuvent ainsi se répartir l'occupation du cache d'une manière bien plus souple que ce qui est permis avec un cache dédié ;; L'implémentation de mécanismes de cohérence des caches est facilitée ;; Elle évite de répliquer des données partagées entre plusieurs threads. Avec l'organisation en caches dédiés, une donnée utilisée par deux threads lancés sur deux coeurs différents doit être présente dans chacun des caches dédiés. Avec un cache partagé, la donnée est présente en une seule fois dans le cache partagé.
Toutefois, quelques inconvénients des caches partagés sont à signaler : Un cache partagé doit avoir une bande passante suffisante pour alimenter plusieurs coeurs, ce qui se fait souvent au détriment de sa latence ;; Un cache partagé doit pouvoir permettre à plusieurs coeurs d'accéder à des données différentes dans le cache simultanément, afin d'éviter de mettre un coeur en attente pendant un accès au cache. Conséquence : ces caches sont des mémoires multiports, ce qui a un impact sur leur consommation énergétique, leur latence, et leur débit binaire ;; Leur grande taille a un impact négatif sur leur latence et leur consommation énergétique ;; Plusieurs programmes peuvent se marcher sur les pieds dans leur répartition de la mémoire cache. Ce phénomène est rare, mais pas impossible.
Dans la réalité, compte tenu de ces contraintes, tous les caches du processeur ne sont pas partagés. Ceux qui ont besoin d'une faible latence (cache L1) sont des caches dédiés, tandis que les autres sont partagés (L2, L3).

Atouts
Avant l'apparition des processeurs multicoeurs, les constructeurs de processeurs augmentaient la puissance de leurs produits en élevant la fréquence de calcul de leurs processeurs monocoeurs. Mais cette méthode a fini par atteindre ses limites. En effet, l'augmentation de fréquence d'un processeur cause rapidement des problèmes de surchauffe, le refroidissement à air (ventilateur) n'étant plus suffisant. Pour lutter contre cette surchauffe, il faut passer à un refroidissement par eau délicat et onéreux, ou bien passer à des ventilations de plus grande taille et vitesse, créatrices de nuisances sonores. D'autre part le besoin croissant en énergie des microprocesseurs était problématique notamment pour les ordinateurs portables.
Les processeurs monocoeurs les plus puissants utilisés dans les ordinateurs de grande distribution ont des fréquences ne dépassant pas en général, les 3 à 4 GHz, car au-delà la température devient trop importante. Dans les salons de technologie, des processeurs sont sur-cadencés grâce au refroidissement à l'azote liquide (température négative).
C'est pour contourner cette limite que les constructeurs se sont tournés vers la fragmentation des puces. Il existait déjà des ordinateurs fonctionnant avec plusieurs processeurs distincts (par exemple, les supercalculateurs). L'idée ici est de reproduire ce parallélisme au sein d'un unique processeur : en bref, introduire plusieurs unités de calcul dans un même processeur. Le principe est simple : plutôt que d'avoir un processeur "simple" à fréquence élevée, on utilise par exemple deux coeurs, de fréquence moitié moindre. On obtient alors un processeur théoriquement de même puissance, mais de fréquence d'horloge plus basse, et de consommation électrique réduite. Le processeur ne rencontre pas les problèmes d'alimentation et de surchauffe de son homologue monocoeur : la puissance dissipée double quand on double les coeurs, alors qu'elle serait quadruplée si on doublait la fréquence d'horloge.
En plus de ces avantages purement techniques, il s'avère que ces microprocesseurs sont également bien plus efficaces dans le traitement multitâche. Sur les systèmes mono-coeurs, le système d'exploitation change régulièrement le programme en cours d'exécution pour passer d'un programme à un autre. Ces changements sont très rapides, et ne sont donc pas visibles par l'utilisateur, qui a l'impression que plusieurs programmes s'exécutent en même temps. Sur les systèmes multi-coeurs, si plusieurs applications sont exécutées simultanément sur l'ordinateur, celui-ci peut dès lors répartir ce travail entre les coeurs de processeurs, plutôt que d'effectuer les opérations en alternance sur un seul processeur.
La notion d'affinité processeur (processor affinity) permet de lier un coeur donné à une application ou à un périphérique pour obtenir une réactivité meilleure (clavier, souris...) tout en évitant des reprises coûteuses de contextes d'exécution par des processeurs distincts.

Contraintes logicielles
Malheureusement, cette approche comporte quelques désavantages, puisque les programmes doivent être repensés pour pouvoir exploiter pleinement les caractéristiques de ces processeurs. En effet, les composants d'un processeur multicoeur ont une puissance individuelle inférieure à celle d'un processeur monocoeur classique ; un logiciel non adapté au multicoeur et qui ne saura donc effectuer ses différents calculs qu'à l'aide d'un seul des coeurs du processeur sera par conséquent exécuté à une vitesse moindre.
En 2006, très peu de logiciels gèrent le bi-coeurs, et globalement les logiciels ne sont pas conçus pour tirer le maximum de cette technologie (excepté dans le monde GNU-Linux où les applications sont portées en très grande majorité - près de 99,8 % - sous plusieurs types d'architectures). Une fois effectuée une mise à niveau de tous les programmes vers la nouvelle architecture, les performances se détacheront nettement dans les applications gourmandes telles que les jeux vidéo.
Ces mises à jour touchent également les systèmes d'exploitation, qui peuvent diviser par eux-mêmes les calculs effectués par les logiciels qu'ils exécutent. La technique multicoeur est alors utilisable même avec des logiciels non adaptés à ce type de traitement, cette utilisation étant cependant moins performante que si le logiciel indique lui-même comment doivent se diviser les calculs. De telles adaptations sont nécessaires à chaque augmentation du nombre de coeurs dans les processeurs. Ce n'est que lorsque celles-ci ont été effectuées que les nouveaux processeurs peuvent être exploités à plein potentiel.
L'industrie des télécommunications a été l'un des premiers à adopter les processeurs multi-coeurs, aussi bien pour la couche d'acheminement des données que pour la couche de commande. Depuis, ces MPU sont en train de remplacer rapidement les processeurs réseaux (NP) qui étaient basés sur des architectures privées à base de microcode et de picocode. 6WIND (en) a été la première société à fournir du logiciel réseau embarqué optimisé pour ces architectures multi-coeurs.
La programmation parallèle bénéficie également du passage à plusieurs coeurs. Des modèles de programmation comme OpenMP, MPI ou OpenHMPP peuvent être utilisés sur ces plates-formes multi-coeurs. D'autres efforts de recherche sont également menés, par exemple le système Sieve de l'éditeur Codeplay (en), les langages Chapel (en) de Cray, Fortress de Sun et X10 d'IBM.

Exemples commerciaux: (en) 6WINDGate. Plan donné et plan de contrôle embarqué parallèle de 6WIND pour les processeurs réseaux multi-coeurs; (fr) National Instruments. Tutoriel sur les principes fondamentaux de la programmation multi-coeur.

Voir aussi

Article connexe: Processeur. Portail de l'informatique; Portail de l'électricité et de l'électronique.