L'induction est historiquement le nom utilisé pour signifier un genre de raisonnement qui se propose de chercher des lois générales à partir de l'observation de faits particuliers, sur une base probabiliste. Actuellement, les programmes scolaires de géographie en collège et lycée impliquent des études de cas représentatives du raisonnement inductif. On induit par exemple des généralités sur la problématique de l'alimentation mondiale à partir de l'étude d'un cas particulier en Inde ou en Éthiopie. Ce fonctionnement pédagogique fondé sur l'étude de cas a été mis en oeuvre auparavant chez les Britanniques.
Remarque : Bien qu'associée dans le titre de cet article à la logique, la présentation qui suit correspond surtout à la notion bayésienne, utilisée consciemment ou non, de l'induction. Dans les ouvrages anglo-saxons de mathématiques, logique et informatique, l'induction complète, désignée sous le nom d'induction (faux-ami) désigne la récurrence, aussi bien dans le raisonnement par récurrence que dans les définitions par récurrence. Le terme est souvent employé pour les généralisations de la récurrence aux bons ordres et aux relations bien fondées. En raisonnement automatisé, l'abduction est un mode de raisonnement qui vise à émettre une hypothèse pour expliquer un fait et elle ne doit pas être confondue avec l'induction présentée ici.

Définition
L'induction est l'inférence menant de plusieurs affirmations particulières à une affirmation. Aristote explique que l'on part de cas individuels pour accéder aux énoncés universels, et l'oppose à la déduction. Cicéron explique : "L'induction, en nous faisant convenir de choses évidentes, tire de ces aveux le moyen de nous faire convenir de choses douteuses, mais qui ont du rapport avec les premières."

Histoire du concept
L'idée de départ de cette conception de l'induction était que la répétition d'un phénomène augmente la probabilité de le voir se reproduire. C'est par exemple la façon dont réagit le cerveau en conditionnement classique. L'accumulation de faits concordants et l'absence de contre-exemples permet, ensuite, d'augmenter le niveau de plausibilité de la loi jusqu'au moment où on choisit par souci de simplification de la considérer comme une quasi-certitude : ainsi en est-il du deuxième principe de la thermodynamique. On n'atteint jamais la certitude "complète" ; tout contre-exemple approprié peut remettre "immédiatement" en cause.
Ensuite, des théorèmes comme celui de Cox ont donné à cette démarche inductive d'abord empirique une base mathématique ferme ; ils ont permis de calculer les probabilités concernées sans aucun arbitraire à une position de départ donnée près.
Mais la définition précédente est assez impropre. Par exemple, on pourrait dire que "cette table-ci est lourde, donc cette table-là est lourde" est un exemple d'induction, mais dans ce cas, il ne s'agit pas de chercher une "loi générale" à partir d'un fait particulier. Plus récemment, l'"induction" en est donc venue à signifier un genre de raisonnement qui n'assure pas la vérité de sa conclusion étant donné les préalables. Ce raisonnement est le contraire de la déduction, qui est un genre de raisonnement où la conclusion ne peut pas être fausse, étant donné les préalables.

Types

Généralisation
Une généralisation (plus précisément, généralisation inductive) procède d'une prémisse portant sur un échantillon à une conclusion à propos d'une population. La proportion Q de l'échantillon a l'attribut A. Par conséquent : La proportion Q de la population a l'attribut A. Exemple: Il y a 20 boules - soit noires soit blanches - dans une urne. Pour estimer leurs nombres respectifs, vous piochez un échantillon de quatre boules et constatez que trois boules sont noires et une est blanche. Une généralisation inductive serait qu'il y a 15 boules noires et cinq blanches dans l'urne.
Syllogisme statistique
Un syllogisme statistique procède d'une généralisation à une conclusion à propos d'un individu. Une proportion Q de la population P a l'attribut A. Un individu X est un membre de P. Par conséquent : Il existe une probabilité, qui correspond à Q, que X ait A. La proportion dans la première prémisse serait quelque chose comme "trois cinquièmes de", "tout", "quelques-uns", etc. Deux sophismes dicto simpliciter peuvent se produire dans les syllogismes statistiques : "accident" et "accident conversé".
Induction simple
L'induction simple procède d'un principe d'un groupe d'échantillon à une conclusion sur une autre personne. "La proportion Q de cas connus de la population P a l'attribut A." "L'individu I est un autre membre de P." "par conséquent :" "Il existe une probabilité correspondant à Q que I possède A."
Ceci est une combinaison d'une généralisation et d'un syllogisme statistique, où la conclusion de la généralisation est aussi le premier prémisse du syllogisme statistique.

Argument d'une analogie
Le processus d'inférence analogique implique de noter les propriétés partagées de deux ou plusieurs choses, et à partir de cette base inférant qu'ils partagent également une autre propriété :P et Q sont semblables en ce qui concerne les propriétés a, b et c.
L'objet P a été observé pour avoir la propriété x en plus.
Par conséquent, Q possède probablement la propriété x aussi.
Le raisonnement analogique est très fréquent dans le sens commun, en science, philosophie et en sciences humaines, mais parfois, il est accepté seulement comme une méthode auxiliaire. Une approche raffinée est le raisonnement par cas.

Inférence causale
Une inférence causale tire une conclusion sur unn de causalité sur la base des conditions de la survenance d'un effet. Les prémisses de la corrélation entre les deux choses peuvent indiquer une relation causale entre les eux, mais d'autres facteurs doivent être pris en compte pour établir la forme exacte de la relation de cause à effet.

Prédiction
Une prédiction tire une conclusion sur un avenir individuel à partir d'un échantillon passé. "La proportion Q des membres observés du groupe G ont eu l'attribut A." "Par conséquent :" "Il y a une probabilité correspondant à Q que d'autres membres du groupe G aient l'attribut A lors de la prochaine observation."
Exemple
Par exemple : Si la loi de la gravitation universelle détermine que, et comment, une pomme qui se détache de son arbre tombera sur le sol, l'observation du mouvement de cette même pomme permet d'établir la loi générale, mais avec une probabilité ou une certitude très faible. Si ensuite, on observe que toutes les pommes et tous les corps tombent de la même façon, si on observe que les corps dans l'espace respectent la même loi, alors la probabilité de la loi augmentera jusqu'à devenir une quasi certitude. Dans le cas de la gravitation universelle, cependant, on a observé que l'orbite de Mercure présentait un effet de précession qui n'était pas expliqué par la loi. La loi de la gravitation universelle est cependant restée considérée comme universellement valide jusqu'à ce qu'Albert Einstein développe la théorie de la relativité générale qui permet d'expliquer entre autres la précession de l'orbite de Mercure. Malgré tout, la gravitation universelle reste utilisée car elle reste valable dans les cas courants, et elle est plus simple à utiliser et à comprendre que la théorie de la relativité.

Ancienne vision de l'induction
De manière générale, l'induction, contrairement à la déduction, est un raisonnement logiquement "inexact", qui est appuyé par sa "vérification" répétée, mais qui peut toujours être démenti par un contre-exemple. Il est cependant universellement utilisé pour deux raisons : À l'exclusion de la logique et des mathématiques qui consistent explicitement à poser des axiomes "arbitraires" (ou "conventionnels) sur la base desquels elles raisonnent par la déduction, toutes les autres sciences tentent de décrire la réalité et ne peuvent le faire, semble t-il, qu'exclusivement sur la base de la "vérification" par l'observation, ce qui les oblige à faire appel à l'induction et leur interdit souvent toute possibilité d'utiliser la déduction pure.; Tous les systèmes vivants semblent fonctionner sur la base de l'induction. L'apprentissage par le cerveau, se basant sur sa confrontation avec la réalité, est essentiellement inductif, et, par extension, en intelligence artificielle, les systèmes d'apprentissage à réseau de neurones se différencient des systèmes algorithmiques en ce qu'ils sont inductifs, alors que les systèmes algorithmiques sont, eux, déductifs. La sélection naturelle, elle-même, en éliminant les "moins adaptés" par la confrontation de l'espèce avec les difficultés de l'existence dans un milieu donné, est aussi un phénomène fondamentalement inductif.
Note : il est assez curieux d'observer que le principe de déduction est infiniment plus simple que le principe d'induction, pourtant, la vie parait s'adapter selon le principe d'induction et, paradoxalement, le cerveau qui est conçu pour l'induction n'est pas qu'une machine logique : il n'intègre pas spontanément et doit acquérir la déduction qui est, pourtant, plus simple.
Il faut remarquer que si l'induction est un raisonnement intrinsèquement probabiliste, il est cependant impossible d'évaluer la probabilité sous-jacente. En effet, celle-ci est une probabilité conditionnelle et elle restera toujours soumise aux choix des conditions de son évaluation, sachant qu'il peut y avoir des conditions auxquelles on n'a pas pensé et qui changeraient, si elles étaient prises en compte, complètement les données du problème.
Exemple : Si je ne rencontre que des chats gris, il me sera facile d'en induire que tous les chats sont gris avec un fort niveau de certitude. Mais si je réalise que le fait que les chats sont gris pourrait être spécifique à la région où je vis, et qu'il pourrait exister une autre région où tous les chats sont roux et encore une autre avec des chats verts (pour prendre une hypothèse réelle ET une hypothèse absurde), mon évaluation de ce niveau de certitude en sera complètement mise en cause.
De plus, le niveau de certitude de ma loi dépendra du coefficient avec lequel j'accepte qu'elle ne soit pas tout à fait universelle et admette des exceptions.
Je peux considérer, par exemple, que la relativité générale, est un cas particulier qui ne s'applique que dans des situations réelles, mais que cela ne met pas en cause en général la théorie de la gravitation universelle, ou au contraire, je peux décider que la gravitation universelle doit être précise et exacte, auquel cas, elle est fausse.

Quelques exemples classiques des limites
La plus célèbre des inductions est probablement l'exemple qu'en donne Aristote : L'âne, le mulet, le cheval vivent longtemps ; or, ce sont là tous les animaux sans fiel ; donc, tous les animaux sans fiel vivent longtemps.
On voit bien que l'induction repose sur une supposition : que "ce sont là tous les animaux sans fiel". Le syllogisme inductif est dit hypothétique (non-scientifique) : La vache est un mammifère ; La vache produit du lait ; donc tous les mammifères produisent du lait.
Un exemple célèbre d'induction abusive cité par Claude Bernard, illustrant la méthode scientifique : un lapin normalement nourri a une urine basique ; le même lapin à jeun a une urine acide ; donc tous les herbivores ont une urine basique ; alors que tous les animaux mal nourris et les carnivores ont une urine acide.
Autre exemple célèbre : la dinde inductiviste de Bertrand Russell.
On voit là l'usage de l'induction : à partir d'observations (qui sont toujours des propositions particulières), l'induction produit des propositions générales hypothétiques qui sont ensuite testables. C'est là, très simplifiée, l'analyse de Claude Bernard, ainsi que celle de Karl Popper.
Hume considérait que l'origine de l'induction (l'idée de connexion) est l'habitude. Si cette habitude produit une croyance en l'induction qui repose surtout sur une "force" (une croyance) psychologique, l'induction conserve cependant, pour lui, une dimension "logique" très importante puisque Hume essaye de formuler dans le Traité de la nature humaine des règles de ce qui rend valable le recours à l'induction. L'induction a donc certes sa source dans la psychologie humaine, mais sa valeur ne s'y réduit pas.
Karl Popper soutient au contraire que "Hume (n'a) jamais reconnu toute la portée de sa propre analyse logique", et il propose un renversement : "au lieu d'expliquer notre propension à présumer l'existence de régularité comme un effet de la répétition, j'ai imaginé d'expliquer ce qui est répétition à nos yeux comme le résultat de notre tendance à supposer et à rechercher de la régularité". Mais, en réalité, Hume ne dit pas autre chose : nous sommes en effet selon lui disposés par l'imagination à trouver de la régularité dans les phénomènes. Sans cette disposition, aucune répétition ne produirait en nous de raisonnement inductif.
Longtemps purement empirique, le processus d'induction a été formalisé par le Théorème de Cox-Jaynes qui confirme la rationalité de la méthode pour la mise à jour des connaissances, la quantifie, et "unifie" l'univers de la logique booléenne avec celui des probabilités (vues non plus en tant que passage à la limite de fréquences, mais comme une traduction numérique d'un état de connaissance dans ce paradigme).

Voir aussi

Articles connexes: Logique; Empirisme; Syllogisme; Raisonnement; Déduction logique (antonyme); Démarche expérimentale; Biais cognitif (exemple : biais de confirmation d'hypothèse),; Méthode des concordances; Concepts logiques; Déduction et induction.