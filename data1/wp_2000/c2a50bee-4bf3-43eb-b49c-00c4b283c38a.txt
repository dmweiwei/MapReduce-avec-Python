Les lois de Moore sont des lois empiriques qui ont trait à l'évolution de la puissance des ordinateurs et de la complexité du matériel informatique. Au sens strict, on ne devrait pas parler de "lois de Moore" mais de "conjectures de Moore" puisque les énoncés de Moore ne sont en fait que des suppositions.
Il existe en fait trois "lois" de Moore, deux authentiques (au sens où elles furent émises par Gordon E. Moore), et une série de "lois" qui ont en commun de se prétendre "loi de Moore" mais qui n'en sont que des simplifications inexactes.

Énoncés
Le premier microprocesseur (Intel 4004) a été inventé en 1971. Il s'agissait d'une unité de calcul de 4 bits, cadencée à 740 kHz et intégrant 2 300 transistors. La capacité d'intégration des transistors et l'augmentation de la finesse de gravure ont amélioré les performances des processeurs. 1) La loi de Moore a été exprimée en 1965 dans le magazine Electronics (en) par Gordon E. Moore, ingénieur de Fairchild Semiconductor, un des trois fondateurs d'Intel. Constatant que la "complexité des semi-conducteurs proposés en entrée de gamme" doublait tous les ans à coût constant depuis 1959, date de leur invention, il postulait la poursuite de cette croissance (en 1965, le circuit le plus performant comportait 64 transistors). Cette augmentation exponentielle fut rapidement nommée "loi de Moore" ou, compte tenu de l'ajustement ultérieur, "première loi de Moore".; 2) En 1975, Moore réévalua sa prédiction en posant que le nombre de transistors des microprocesseurs (et non plus de simples circuits intégrés moins complexes car formés de composants indépendants) sur une puce de silicium double tous les deux ans. Bien qu'il ne s'agisse pas d'une loi physique mais seulement d'une extrapolation empirique, cette prédiction s'est révélée étonnamment exacte. Entre 1971 et 2001, la densité des transistors a doublé chaque 1,96 année. En conséquence, les machines électroniques sont devenues de moins en moins coûteuses et de plus en plus puissantes.; 3) Une version commune, variable et sans lien avec les énoncés réels de Moore est : "quelque chose" double tous les dix-huit mois, cette chose étant "la puissance", "la capacité", "la vitesse", "la fréquence d'horloge" et bien d'autres variantes mais très rarement la densité des transistors sur une puce. Ces pseudo "lois de Moore" sont celles le plus souvent diffusées, car elles fleurissent dans des publications grand public et sur de nombreux sites Internet. Leur seul point commun est donc ce nombre de dix-huit mois, qu'on ne trouve pourtant dans aucun des deux énoncés de Moore.

Loi de Moore et fréquence d'horloge
L'interprétation erronée de la loi de Moore sur la fréquence d'horloge est à peu près vérifiée depuis 1973, et aurait dû théoriquement continuer jusqu'en 2015 avant qu'on ne bute sur des effets de bruits parasites (effets quantiques, désintégrations alpha). Depuis 2004, la fréquence des processeurs tend à stagner en raison de difficultés de dissipation thermique, qui empêchent une montée en fréquence en dépit de la taille plus faible des composants. Les fréquences de processeurs montent à ce jour au-delà de 5 GHz, un record de 500 GHz a été battu par IBM (en coopération avec Georgia Tech) avec un transistor équipé d'une puce à base de silicium-germanium qui, pour l'occasion, a été refroidi à 269 C à l'hélium liquide. Ce transistor fonctionne encore à 350 GHz à température ambiante.
Cependant la seconde loi de Moore est toujours respectée, du fait de la capacité d'intégration des processeurs toujours en progression, qui permet de contourner la stagnation de la fréquence par le doublement sur une puce du nombre de transistors, la fréquence restant pour sa part inchangée (Dual PowerPC en 2002, Dual IA en 2004, Intel Core Duo en 2006).
De plus, on expérimente des puces fonctionnant en mode totalement asynchrone. L'idée de circuits asynchrones n'est pas nouvelle puisqu'elle a été expérimentée en 1951 avec l'IAS et en 1952 avec l'ORDVAC. On s'aperçoit en effet que la simple transmission du signal d'horloge à tous les composants peut consommer la moitié de l'espace et de la puissance électrique des microprocesseurs de l'an 2000.

Parallélisme et loi de Moore
Le recours au traitement parallèle est devenu récemment nécessaire pour que la loi de Moore reste valide. Pendant des années, les fondeurs de processeurs étaient en mesure de fournir des augmentations de fréquence d'horloge et des améliorations de parallélisme au niveau des jeux d'instructions, de telle manière que les applications mono-thread s'exécutaient beaucoup plus vite sur une nouvelle génération de processeurs sans qu'aucune modification ne soit nécessaire. Désormais, pour gérer au mieux la puissance dissipée (directement liée à la fréquence d'horloge), les fondeurs favorisent les architectures multi-coeurs. Ceci a un impact extrêmement important sur le logiciel qui doit être écrit et spécialement adapté pour tirer avantage du matériel.

Autres facteurs

Aspects financiers
Un autre facteur peut freiner la progression des performances des processeurs, et qui n'a cette fois-ci plus rien de physique, mais qui est d'ordre financier. Le coût des chaînes de production augmente lui aussi exponentiellement, à un point tel que même des géants concurrents comme IBM et Siemens ont dû grouper leurs investissements pour arriver à suivre le mouvement.
La rentabilité des nouvelles générations de machines dépend d'un futur pour le moins incertain (beaucoup d'utilisateurs de PC, par exemple, commencent à prendre comme critère de choix prioritaire non plus la vitesse d'un PC, mais son niveau de bruit) et il se pourrait que dans ces conditions ce soit une décision économique, et non un palier physique, qui mette fin à la loi de Moore.

Vitesse réelle et vitesse subjective
Des machines de plus en plus puissantes mises à disposition des développeurs ont des effets pervers. À l'époque des processeurs "lents" des années 1980 et 1990, les développeurs investissaient beaucoup de temps pour optimiser les programmes et chaque ligne de code que l'on pouvait économiser permettait de gagner des cycles d'horloge et donc d'aller plus vite. Les ordinateurs actuels offrent un confort de travail qui a pour effet de diminuer la vigilance des développeurs. En outre, les contraintes économiques obligent à toujours produire dans l'urgence, et le temps passé autrefois à optimiser le code a été sacrifié. Ainsi est-on confronté aujourd'hui à un paradoxe : les ordinateurs sont de plus en plus rapides, mais les logiciels de plus en plus lourds et de plus en plus lents (voir Loi de Wirth). Finalement, l'utilisateur n'a pas la sensation d'une réelle augmentation de la vitesse, surtout pour des tâches élémentaires comme le traitement de texte. Nombre d'utilisateurs regrettent même les ordinateurs plus "rustiques" qui, privés de tous les gadgets dont les systèmes sont chargés aujourd'hui, pouvaient s'avérer plus performants en termes de productivité. Un autre facteur sans doute explique mieux l'absence de sensation de progrès : les autres composants des ordinateurs n'ont pas forcément évolué aussi vite. Dans un ordinateur moderne équipé de disques durs mécaniques ce sont ces derniers qui sont le facteur limitant de l'expérience utilisateur. Un ordinateur est un système comparable à une chaîne : le composant le plus lent décide de la vitesse de l'ensemble. L'ajout de mémoire vive ou l'installation d'un stockage SSD dans un système obsolète ou bas de gamme permet un gain de réactivité (démarrage de la machine, lancement des programmes, arrêt) souvent plus apprécié par l'utilisateur qu'une augmentation de la vitesse du processeur.

Contrainte économique
La loi de Moore pourrait également présenter un intérêt économique de contrôle de la demande par répartition distillée de l'offre. En effet, la miniaturisation progresse en principe grâce à des découvertes et à des optimisations ponctuelles, réalité peu conforme à la régularité de l'évolution exponentielle spécifiée par la loi de Moore. En maîtrisant dans le temps la diffusion des applications technologiques nouvelles, il est possible que les géants des semi-conducteurs définissent eux-mêmes un modèle stable de consommation, et s'assurent ainsi d'une correspondance entre leurs efforts d'innovation et les désirs de renouvellement de leur clientèle. L'auto-limitation de l'offre obligerait ainsi les consommateurs à mettre à jour régulièrement leur matériel. Pour être effective, il faudrait néanmoins qu'une telle auto-limitation de l'offre puisse s'appuyer sur une cartellisation forte du marché.
Dans ce cas, assez courant dans l'histoire du capitalisme, les lois du marché favoriseraient le bridage de l'innovation pour assurer une rente à l'ensemble du secteur concerné

The Wall (en français : Le Mur)
La loi de Moore s'est jusqu'ici révélée étonnamment exacte, et elle pourrait en principe le rester jusque vers 2015 avant qu'on ne soit réellement confronté aux effets quantiques, car vers 2015, les processeurs devraient contenir plus de 15 milliards de transistors.
En 1999, le transistor CMOS dit "ultime" développé au CEA-Leti à Grenoble a poussé à ses "limites" le principe du transistor MOSFET avec une section de 18 nanomètres (la dimension d'environ 70 atomes mis côte à côte), soit sept fois plus petit que le plus petit transistor industriel de 2002 (123 nm en 2002, 83 nm en 2003, 65 nm fin 2005, 45 nm fin 2008, 32 nm fin 2010, 22 nm fin 2012, 14 nm fin 2016). Il permettait un degré d'intégration théorique de sept milliards de jonctions sur une pièce d'un euro. Mais, il ne s'agissait là que d'une simple expérience de recherche pour étudier le fonctionnement des techniques CMOS lorsque l'on s'approche de la taille moléculaire.
Le coût de la technique permettant la réalisation de puces intégrant de plus en plus de transistors augmente dans des proportions vertigineuses. Une autre loi empirique de la Silicon Valley, la loi de Rock, stipule ainsi que le coût de fabrication d'une fonderie de puce double tous les quatre ans car le procédé de fabrication utilisé depuis une quarantaine d'années, la photolithographie, se rapproche toujours plus de ses limites physiques. Ainsi en 2004, Intel a annoncé un investissement de plus de deux milliards de dollars dans son usine Fab12 en Arizona pour la fabrication de puces à partir de wafers de 300 mm de diamètre, qui ont remplacé les wafers de 200 mm vers la fin 2005.
Pour fabriquer des transistors toujours plus minuscules, on utilise des rayonnements de longueur d'onde toujours plus courte et la course à la miniaturisation entraînera la photolithographie dans le spectre des rayons X de plus en plus durs (rayonnement UV puis rayons X...). Mais dans cette gamme de longueurs d'ondes il devient difficile, voire impossible, de concentrer efficacement les rayons. Au milieu des années 1990, on estimait ne pas être en mesure de fabriquer industriellement des transistors de moins de 400 atomes (100 nm) de section avec un tel procédé. Dans l'industrie du silicium, cette limite s'appelle "the Wall".

Changement progressif des besoins, développement durable

Nouveaux besoins
Certains commentateurs mettent en doute la pertinence de la loi de Moore en matière de développement durable : le doublement périodique de la puissance a pour effet de diminuer la durée d'amortissement des équipements, donc de générer des déchets ;; l'un des problèmes posés est la consommation électrique, plus que la puissance de calcul.
Les nouveaux besoins (informatique "verte", diminution de la taille des ordinateurs avec les netbooks et tablettes...) s'expriment moins en termes de millions de transistors par mm qu'en performance par énergie consommée.
Par ailleurs, faire descendre le traitement d'une tâche interactive de 20 secondes à 2 secondes, puis à 200 ms, est intéressant. Le faire tomber ensuite à 20 ms n'apporte pas nécessairement quelque chose, et certainement rien si cette tâche est isolée. Si les besoins industriels réclament de plus en plus de puissance, il n'en va pas indéfiniment de même de ceux du particulier.
On voit émerger les besoins des parties prenantes des entreprises, qui réclament que soient pris en compte les impacts environnementaux et sociaux de leur activité en matière de développement durable.
Un rapport d'information du Sénat français sur les nouvelles techniques de l'information mentionne la loi de Moore comme la principale accélération technique de ces dernières décennies. Ce rapport souligne la nécessité de définir un système de valeurs dans la nouvelle société de l'information, qui évite le scientisme.
Dans ce contexte, on est amené à évaluer la performance par watt.

Initiatives
Le Green500 List classe les superordinateurs de la liste TOP500 en termes d'efficacité énergétique. Celle-ci est mesurée en FLOPS par watt.
Le constructeur informatique Bull a abandonné la loi de Moore dans ses objectifs, et retient maintenant le rapport performance - énergie dans ses plans d'informatique verte.
Certains constructeurs comme ARM introduisent des processeurs ne cherchant plus à suivre la loi de Moore. Ses processeurs de 2009 possèdent parfois 100 000 transistors, soit moins qu'un processeur Intel 286 à 12 MHz de 1982, mais ne consomment qu'un quart de watt, équipant en 2009 une dizaine de modèles de netbooks fonctionnant sous Linux ou d'autres systèmes d'exploitation.
La création en 2007 de la Climate Savers Computing Initiative, qui s'est fixé pour objectif de réduire de moitié la consommation électrique des ordinateurs, a probablement signé l'arrêt de mort de la loi de Moore.
Voir aussi : Informatique et développement durable,; Performance par watt.

Changement de paradigme
Lorsque la loi de Moore aura atteint ses limites, changer de paradigme consistera en la transition de la microélectronique aux nanotechnologies. C'est-à-dire un ensemble de techniques radicalement différentes, complémentaires ou concurrentes, telles que l'utilisation des nanotubes dans les transistors moléculaires, les ordinateurs à ADN, l'informatique quantique... Technologies couramment regroupées sous le vocable "nano-informatique" qui introduisent notamment les systèmes ubiquitaires et l'informatique diffuse.
Lors de l'Intel Developer Forum de septembre 2007, Gordon Moore a prédit que sa loi de doublement du nombre de transistors dans une puce tous les deux ans ne serait plus valide dans dix à quinze ans. En effet, l'industrie approche de plus en plus des limites physiques de la micro-électronique, où les transistors ne seront plus constitués que de quelques atomes et l'isolant entre eux. L'industrie devra alors chercher des méthodes entièrement nouvelles, tel que l'empilement des transistors en trois dimensions.
En février 2016, la fin d'application de la loi de Moore est annoncée par ZDnet, avec quelques explications venant de Shekhar Borkar, responsable de recherches chez Intel.

Puces mémoires : quelques repères
(Indiqués par Gordon Bell dans son exposé "Computing laws")
Selon la loi de Moore : 1980 : 64 kbit; 1983 : 256 kbit; 1985 : 1 Mbit; 1987 : 4 Mbit; 1990 : 16 Mbit; 1993 : 64 Mbit; 1996 : 256 Mbit; 1999 : 1 Gbit; 2005 : 3 Gbit; 2007 : 3 Gbit 8.

Voir aussi

Articles connexes: Chronologie des microprocesseurs; Liste des ordinateurs à transistors; Loi de Wirth; Loi de Koomey; Singularité technologique; Climate Savers Computing Initiative; Technologies de l'exponentiel : NBIC.