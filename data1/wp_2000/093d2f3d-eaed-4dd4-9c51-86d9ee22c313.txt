Un microprocesseur est un processeur dont tous les composants ont été suffisamment miniaturisés pour être regroupés dans un unique boitier. Fonctionnellement, le processeur est la partie d'un ordinateur qui exécute les instructions et traite les données des programmes.
Un Intel 4004 dans son boîtier à 16 broches, premier microprocesseur commercialisé. Architecture de l'Intel 4004 L'intérieur d'un Intel 80486DX2.

Description
Jusqu'au début des années 1970, les différents composants électroniques formant un processeur ne pouvaient pas tenir sur un seul circuit intégré, ce qui nécessitait d'interconnecter de nombreux composants dont plusieurs circuits intégrés. En 1971, la société américaine Intel réussit, pour la première fois, à placer tous les composants qui constituent un processeur sur un seul circuit intégré donnant ainsi naissance au microprocesseur.
Cette miniaturisation a permis : d'augmenter les vitesses de fonctionnement des processeurs, grâce à la réduction des distances entre les composants ;; de réduire les coûts, grâce au remplacement de plusieurs circuits par un seul ;; d'augmenter la fiabilité : en supprimant les connexions entre les composants du processeur, on supprime l'un des principaux vecteurs de panne ;; de créer des ordinateurs bien plus petits : les micro-ordinateurs ;; de réduire la consommation énergétique.
Les principales caractéristiques d'un microprocesseur sont : Le jeu d'instructions qu'il peut exécuter. Voici quelques exemples d'instructions que peut exécuter un microprocesseur : additionner deux nombres, comparer deux nombres pour déterminer s'ils sont égaux, comparer deux nombres pour déterminer lequel est le plus grand, multiplier deux nombres... Un processeur peut exécuter plusieurs dizaines, voire centaines ou milliers, d'instructions différentes.; La complexité de son architecture. Cette complexité se mesure par le nombre de transistors contenus dans le microprocesseur. Plus le microprocesseur contient de transistors, plus il pourra effectuer des opérations complexes, et-ou traiter des nombres de grande taille.; Le nombre de bits que le processeur peut traiter ensemble. Les premiers microprocesseurs ne pouvaient traiter plus de 4 bits d'un coup. Ils devaient donc exécuter plusieurs instructions pour additionner des nombres de 32 ou 64 bits.; Les microprocesseurs actuels (en 2007) peuvent traiter des nombres sur 64 bits. Le nombre de bits des bus, de la mémoire et du processeur est en rapport direct avec la capacité à traiter de grands nombres rapidement, ou des nombres d'une grande précision (nombres de décimales significatives).; La vitesse de l'horloge. Le rôle de l'horloge est de cadencer le rythme du travail du microprocesseur. Plus la vitesse de l'horloge augmente, plus le microprocesseur effectue d'instructions en une seconde.
Tout ceci est théorique, dans la pratique, selon l'architecture du processeur, le nombre de cycles d'horloge pour réaliser une opération élémentaire peut varier d'un cycle à plusieurs dizaines par unité d'exécution (typiquement une sur un processeur classique).
Par exemple, un processeur A cadencé à 400 MHz peut exécuter certaines instructions plus rapidement qu'un autre B cadencé à 1 GHz, tout dépend de leurs architectures respectives.
La combinaison des caractéristiques précédentes détermine la puissance du microprocesseur qui s'exprime en "millions d'instructions par seconde" (MIPS). Dans les années 1970, les microprocesseurs effectuaient moins d'un million d'instructions par seconde, mais en 2007, les processeurs pouvaient effectuer plus de 10 milliards d'instructions par seconde.

Histoire
En 1969, le microprocesseur a été inventé par un ingénieur et un physicien d'Intel : Marcian Hoff (surnommé Ted Hoff) et Federico Faggin. Marcian Hoff a formulé l'architecture du microprocesseur (une architecture de bloc et un jeu d'instructions). Le premier microprocesseur commercialisé, le 15 novembre 1971, est l'Intel 4004 4 bits, suivi par l'Intel 8008 à 8 bits et qui servi initialement à fabriquer des contrôleurs graphiques en mode texte. Jugé trop lent par le client qui en avait demandé la conception, il devint un processeur d'usage général.
Ces processeurs sont les précurseurs des Intel 8080, Zilog Z80, et de la future famille des Intel x86. Federico Faggin est l'auteur d'une méthodologie de conception nouvelle pour la puce et la logique, fondée pour la première fois sur la technologie silicon gate développé par lui en 1968 chez Fairchild. Il a aussi dirigé la conception du premier microprocesseur jusqu'à son introduction sur le marché en 1971.
Dans les années 1970, apparaissent les concepts de datagramme et d'informatique distribuée, avec Arpanet, le réseau Cyclades et la Distributed System Architecture, devenue en 1978 le modèle "OSI-DSA". Le microprocesseur est très vite accueilli comme la pierre angulaire de cette informatique distribuée, car il permet de décentraliser le calcul, avec des machines moins coûteuses et moins encombrantes face au monopole IBM, produites en plus grande série. En 1990, Gilbert Hyatt a revendiqué la paternité du microprocesseur en se basant sur un brevet qu'il avait déposé en 1970. La reconnaissance de l'antériorité du brevet de Hyatt aurait permis à ce dernier de réclamer des redevances sur tous les microprocesseurs fabriqués de par le monde. Cependant, le brevet de Hyatt a été invalidé en 1995 par l'office américain des brevets, sur la base du fait que le microprocesseur décrit dans la demande de brevet n'avait pas été réalisé, et n'aurait d'ailleurs pas pu l'être avec la technologie disponible au moment du dépôt du brevet. Le tableau suivant décrit les principales caractéristiques des microprocesseurs fabriqués par Intel, et montre leur évolution en termes de nombre de transistors, en miniaturisation des circuits, et en augmentation de puissance. Il faut garder à l'esprit que si ce tableau décrit l'évolution des produits d'Intel, l'évolution des produits des concurrents a suivi avec plus ou moins d'avance ou de retard la même marche.
Un programme informatique est, par essence, un flux d'instructions exécutées par un processeur. Chaque instruction nécessite un à plusieurs cycles d'horloge, l'instruction est exécutée en autant d'étapes que de cycles nécessaires. Les microprocesseurs séquentiels exécutent l'instruction suivante lorsqu'ils ont terminé l'instruction en cours. Dans le cas du parallélisme d'instructions, le microprocesseur pourra traiter plusieurs instructions dans le même cycle d'horloge, à condition que ces instructions différentes ne mobilisent pas simultanément une unique ressource interne. Autrement dit, le processeur exécute des instructions qui se suivent, et ne sont pas dépendantes l'une de l'autre, à différents stades d'achèvement. Cette file d'exécution à venir s'appelle un pipeline. Ce mécanisme a été implémenté la première fois dans les années 1960 par IBM. Les processeurs plus évolués exécutent en même temps autant d'instructions qu'ils ont de pipelines, ce à la condition que toutes les instructions à exécuter parallèlement ne soient pas interdépendantes, c'est-à-dire que le résultat de l'exécution de chacune d'entre elles ne modifie pas les conditions d'exécution de l'une des autres. Les processeurs de ce type sont appelés processeurs superscalaires. Le premier ordinateur à être équipé de ce type de processeur était le Seymour Cray CDC 6600 en 1965. Le Pentium est le premier des processeurs superscalaires pour compatible PC.
Les concepteurs de processeurs ne cherchent pas simplement à exécuter plusieurs instructions indépendantes en même temps, ils cherchent à optimiser le temps d'exécution de l'ensemble des instructions. Par exemple le processeur peut trier les instructions de manière que tous ses pipelines contiennent des instructions indépendantes. Ce mécanisme s'appelle l'exécution out-of-order. Ce type de processeur s'est imposé pour les machines grand public des années 1980 et aux années 1990. L'exemple canonique de ce type de pipeline est celui d'un processeur RISC, en cinq étapes. Le Intel Pentium 4 dispose de 35 étages de pipeline. Un compilateur optimisé pour ce genre de processeur fournira un code qui sera exécuté plus rapidement.
Pour éviter une perte de temps liée à l'attente de nouvelles instructions, et surtout au délai de rechargement du contexte entre chaque changement de threads, les fondeurs ont ajouté à leurs processeurs des procédés d'optimisation pour que les threads puissent partager les pipelines, les caches et les registres. Ces procédés, regroupés sous l'appellation Simultaneous Multi Threading, ont été mis au point dans les années 1950. Par contre, pour obtenir une augmentation des performances, les compilateurs doivent prendre en compte ces procédés, il faut donc re-compiler les programmes pour ces types de processeurs. Intel a commencé à produire, début des années 2000, des processeurs implémentant la technologie SMT à deux voies. Ces processeurs, les Pentium 4, peuvent exécuter simultanément deux threads qui se partagent les mêmes pipelines, caches et registres. Intel a appelé cette technologie SMT à deux voies : l'Hyperthreading. Le Super-threading est, quant à lui, une technologie SMT dans laquelle plusieurs threads partagent aussi les mêmes ressources, mais ces threads ne s'exécutent que l'un après l'autre et non simultanément.
Depuis longtemps déjà, existait l'idée de faire cohabiter plusieurs processeurs au sein d'un même composant, par exemple les System on Chip. Cela consistait, par exemple, à ajouter au processeur, un coprocesseur arithmétique, un DSP, voire un cache mémoire, éventuellement même l'intégralité des composants que l'on trouve sur une carte mère. Des processeurs utilisant deux ou quatre coeurs sont donc apparus, comme le POWER4 d'IBM sorti en 2001. Ils disposent des technologies citées préalablement. Les ordinateurs qui disposent de ce type de processeurs coûtent moins cher que l'achat d'un nombre équivalent de processeurs, cependant, les performances ne sont pas directement comparables, cela dépend du problème traité. Des API spécialisées ont été développées afin de tirer parti au mieux de ces technologies, comme le Threading Building Blocks d'Intel. Date : l'année de commercialisation du microprocesseur.; Nom : le nom du microprocesseur.; Nombre de transistors : le nombre de transistors contenus dans le microprocesseur.; Finesse de gravure (nm) : la largeur minimale possible (en nanomètres) du canal des transistors, elle sert indirectement d'unité de base (lambda) dans le dimensionnement des autres structure du circuit. En comparaison, l'épaisseur d'un cheveu humain est de 100 microns - 100 000 nm. Le diamètre d'un atome de silicium est de l'ordre de 100 pm-0,1 nm. En 2014, à des finesses de gravure de l'ordre de 10 nm (pour la mémoire), on se retrouve avec certaine structure (comme la couche d'isolation de la grille des transistors) ayant une épaisseur de moins de 4 nm, ce qui fait quelque dizaines d'atomes de silicium. En augmentant la finesse de gravure, on se rapproche des limites en deçà desquelles le comportement électrique des matériaux relève de moins en moins de la physique classique, mais de plus en plus de la mécanique quantique (les électrons traversant la grille des transistors par effet tunnel).; Fréquence de l'horloge : la fréquence du signal d'horloge interne qui cadence le microprocesseur. MHz - million(s) de cycles par seconde. GHz - milliard(s) de cycles par seconde.; Largeur des données : le premier nombre indique le nombre de bits sur lequel une opération est faite. Le second nombre indique le nombre de bits transférés à la fois entre la mémoire et le microprocesseur.; MIPS : le nombre de millions d'instructions, sur des entiers, effectuées par le microprocesseur en une seconde.

Familles
Microprocesseur PowerPC 4755. Microprocesseur ARM60. Microprocesseur Intel Core 2 Duo.
Les microprocesseurs sont habituellement regroupés en familles, en fonction du jeu d'instructions qu'ils exécutent. Si ce jeu d'instructions comprend souvent une base commune à toute la famille, les microprocesseurs les plus récents d'une famille peuvent présenter de nouvelles instructions. La rétrocompatibilité au sein d'une famille n'est donc pas toujours assurée. Par exemple un programme dit compatible x86 écrit pour un processeur Intel 80386, qui permet la protection mémoire, pourrait ne pas fonctionner sur des processeurs antérieurs, mais fonctionne sur tous les processeurs plus récents (par exemple un Core Duo d'Intel ou un Athlon d'AMD).
Il existe des dizaines de familles de microprocesseurs. Parmi celles qui ont été les plus utilisées, on peut citer :
La famille la plus connue par le grand public est la famille x86, apparue à la fin des années 1970, développée principalement par les entreprises Intel (fabricant du Pentium), AMD (fabricant de l'Athlon), VIA et Transmeta. Les deux premières entreprises dominent le marché en fabriquant la majorité des microprocesseurs pour micro-ordinateurs compatibles PC et Macintosh depuis 2006.
Le MOS Technology 6502 qui a servi à fabriquer les Apple II, Commodore PET, et dont les descendants ont servi au Commodore 64 et aux consoles Atari 2600. Le MOS Technology 6502 a été conçu par d'anciens ingénieurs de Motorola et était très inspiré du Motorola 6800.
Le microprocesseur Zilog Z80 a été largement utilisé dans les années 1980 dans la conception des premiers micro-ordinateurs personnels 8 bits comme le TRS-80, les Sinclair ZX80, ZX81, ZX Spectrum, le standard MSX, les Amstrad CPC et plus tard dans les systèmes embarqués.
La famille Motorola 68000 (aussi appelée m68k) de Motorola animait les premiers Macintosh, les Mega Drive, les Atari ST et les Commodore Amiga. Leurs dérivés (Dragonball, ColdFire) sont toujours utilisés dans des systèmes embarqués.
Les microprocesseurs PowerPC d'IBM et de Motorola équipaient jusqu'en 2006 les micro-ordinateurs Macintosh (fabriqués par Apple). Ces microprocesseurs sont aussi utilisés dans les serveurs de la série P d'IBM et dans divers systèmes embarqués. Dans le domaine des consoles de jeu, des microprocesseurs dérivés du PowerPC équipent la Wii (Broadway), la GameCube (Gekko), Xbox 360 (dérivé à trois coeurs nommé Xenon). La PlayStation 3 est équipée du microprocesseur Cell, dérivé du POWER4, une architecture proche de PowerPC.
Les processeurs d'architecture MIPS animaient les stations de travail de Silicon Graphics, des consoles de jeux comme la PSone, la Nintendo 64 et des systèmes embarqués, ainsi que des routeurs Cisco. C'est la première famille à proposer une architecture 64 bits avec le MIPS R4000 en 1991. Les processeurs du fondeur chinois Loongson, sont une nouvelle génération basées sur les technologies du MIPS, utilisés dans des supercalculateurs et des ordinateurs faible consommation.
La famille ARM est de nos jours utilisée uniquement dans les systèmes embarqués, dont de nombreux PDA et smartphones. Elle a précédemment été utilisée par Acorn pour ses Archimedes et RiscPC.

Rapidité d'exécution des instructions

Fréquence de fonctionnement
Les microprocesseurs sont cadencés par un signal d'horloge (signal oscillant régulier imposant un rythme au transfert entre circuit). Au milieu des années 1980, ce signal avait une fréquence de 4 à 8 MHz. Dans les années 2000, cette fréquence atteint 3 GHz. Plus cette fréquence est élevée, plus le microprocesseur peut exécuter à un rythme élevé les instructions de base des programmes mais plus la qualité des bus doit être soignée et leur longueur adaptée à la fréquence.
L'augmentation de la fréquence présente des inconvénients : la dissipation thermique d'un circuit donné est proportionnelle au carré de sa fréquence de fonctionnement : cela implique d'avoir une solution de refroidissement du processeur adaptée ;; la fréquence est notamment limitée par les temps de commutation des portes logiques : il est nécessaire qu'entre deux "coups d'horloge", les signaux numériques aient eu le temps de parcourir tout le trajet nécessaire à l'exécution de l'instruction attendue ; pour accélérer le traitement, il faut agir sur de nombreux paramètres (taille d'un transistor, interactions électromagnétiques entre les circuits, etc.) qu'il devient de plus en plus difficile d'améliorer (tout en s'assurant de la fiabilité des opérations).

Overclocking
L'overclocking consiste à appliquer au microprocesseur une fréquence du signal d'horloge supérieure aux recommandations du fabricant ce qui permet d'exécuter plus d'instructions à chaque seconde. Cela nécessite souvent plus de puissance d'alimentation au risque de dysfonctionnements voire de destruction en cas de surchauffe.

Optimisation du chemin d'exécution
Les microprocesseurs actuels sont optimisés pour exécuter plus d'une instruction par cycle d'horloge, ce sont des microprocesseurs avec des unités d'exécution parallélisées. De plus ils sont dotés de procédures qui "anticipent" les instructions suivantes avec l'aide de la statistique.
Dans la course à la puissance des microprocesseurs, deux méthodes d'optimisation sont en concurrence : la technologie RISC (Reduced Instruction Set Computer, jeu d'instructions simple), rapide avec des instructions simples de taille standardisée, facile à fabriquer et dont on peut monter la fréquence de l'horloge sans trop de difficultés techniques ;; la technologie CISC (Complex Instruction Set Computer), dont chaque instruction complexe nécessite plus de cycles d'horloge, mais qui a en son coeur beaucoup d'instructions précâblées.
Néanmoins, avec la diminution de la taille des puces électroniques et l'accélération des fréquences d'horloge, la distinction entre RISC et CISC a quasiment complètement disparu. Là où des familles tranchées existaient, on observe aujourd'hui des microprocesseurs où une structure interne RISC apporte de la puissance tout en restant compatible avec une utilisation de type CISC (la famille Intel x86 a ainsi subi une transition entre une organisation initialement très typique d'une structure CISC. Actuellement elle utilise un coeur RISC très rapide, s'appuyant sur un système de réarrangement du code à la volée) mis en oeuvre, en partie, grâce à des mémoires caches de plus en plus grandes, comportant jusqu'à trois niveaux.

Structure et fonctionnement

Structure d'un microprocesseur
L'unité centrale d'un microprocesseur comprend essentiellement : une unité arithmétique et logique (UAL) qui effectue les opérations ;; des registres qui permettent au microprocesseur de stocker temporairement des données ;; une unité de contrôle qui commande l'ensemble du microprocesseur en fonction des instructions du programme.
Certains registres ont un rôle très particulier : le registre indicateur d'état (flags), ce registre donne l'état du microprocesseur à tout moment, il peut seulement être lu ;; le compteur de programme (PC, Program Counter), il contient l'adresse de la prochaine instruction à exécuter ;; le pointeur de pile (SP, Stack Pointer), c'est le pointeur d'une zone spéciale de la mémoire appelée pile où sont rangés les arguments des sous-programmes et les adresses de retour.
Seul le Program Counter est indispensable, il existe de (rares) processeurs ne comportant pas de registre d'état ou pas de pointeur de pile (par exemple le NS320xx (en)).
L'unité de contrôle peut aussi se décomposer : le registre d'instruction, mémorise le code de l'instruction à exécuter ;; le décodeur décode cette instruction ;; le séquenceur exécute l'instruction, c'est lui qui commande l'ensemble des organes du microprocesseur.

Fonctionnement
Pour commencer, le microprocesseur va charger une instruction contenue en mémoire grâce au compteur de programme. Ce dernier est au passage incrémenté, afin que le processeur traite l'instruction suivante au prochain cycle. L'instruction est alors décodée et si nécessaire le microprocesseur va chercher en mémoire les données supplémentaires. Dans certains cas, des instructions servent uniquement à charger une donnée dans un registre précis ou à écrire une donnée d'un registre en mémoire. Dans ce cas, le processeur charge ou écrit la donnée puis passe à l'instruction suivante. Dans le cas où le processeur doit effectuer une opération de calcul, le processeur fait alors appel à l'ALU. Dans beaucoup d'architectures, celle-ci fonctionne avec un registre accumulateur. Celui-ci enregistre le résultat de l'opération précédente, qui peut ensuite être réutilisé. Dans le cas d'un saut (goto, jump), c'est le compteur de programme qui est directement modifié. Dans le cas d'un saut conditionnel (if), le processeur vérifie avant le saut qu'une condition booléenne est valide (true). Dans certains sauts (jump), le processeur ajoute une valeur à l'accumulateur. Cela permet au programme d'être exécuté à n'importe quel endroit dans la mémoire. Les instructions se divisent donc en plusieurs catégories: Les instructions de chargement (load): mettent l'accumulateur à une certaine valeur;; Les instructions de rangement (store): permettent d'écrire la valeur de l'accumulateur dans un registre ou un emplacement de mémoire précis;; Les instructions de saut (if, jump): permettent de déplacer choisir la prochaine instruction à exécuter;; Les instructions de calcul (add, mul, div, etc.): permettent par exemple d'ajouter le contenu du registre X à l'accumulateur, de multiplier l'accumulateur par le registre Y, etc.
À la fin du cycle, le processeur fini de ranger ses données en mémoire ou dans les registres spécifiques. En cas de retenue, un registre spécial reçoit la valeur de la retenue, ce qui permet de le combiner à nouveau pour fonctionner avec plus de bits que ce que permet l'architecture. En cas d'erreur, comme une division par zéro, le processeur modifie un registre d'état et peut déclencher une interruption. Toutes ces étapes peuvent s'effectuer en plusieurs cycles d'horloge. Une optimisation consiste à les exécuter à la chaîne (principe du pipeline) ou en parallèle (architecture superscalaire). Actuellement, face à la difficulté lié à la montée en fréquence des microprocesseurs, les fabricants tentent d'augmenter le nombre d'Instructions Par Cycle (IPC) afin d'augmenter la vitesse de leurs processeurs. Cela a conduit à l'apparition de processeurs multi-coeurs, composés de plusieurs unités, ou coeur, capables d'exécuter une instruction indépendamment de l'autre (contrairement à une architecture superscalaire, qui conserve des registres en commun). On parle alors de calcul en parallèle. Néanmoins, cela nécessite des programmes adaptés et les performances de ces processeurs dépendent donc de plus en plus de la qualité de programmation des programmes qu'ils exécutent.

Fabrication
La fabrication d'un microprocesseur est essentiellement identique à celle de n'importe quel circuit intégré. Elle suit donc un procédé complexe. Mais l'énorme taille et complexité de la plupart des microprocesseurs a tendance à augmenter encore le coût de l'opération. La loi de Moore, qui indique que le nombre de transistors des microprocesseurs sur les puces de silicium double tous les deux ans, indique également que les coûts de production doublent en même temps que le degré d'intégration.
La fabrication des microprocesseurs est aujourd'hui considérée comme l'un des deux facteurs d'augmentation de la capacité des unités de fabrication (avec les contraintes liées à la fabrication des mémoires à grande capacité). La finesse de la gravure industrielle a atteint 45 nm en 2006. En diminuant encore la finesse de gravure, les fondeurs se heurtent aux règles de la mécanique quantique.

Problème d'échauffement
Malgré l'usage de techniques de gravures de plus en plus fines, l'échauffement des microprocesseurs reste approximativement proportionnel au carré de leur tension à architecture donnée. Avec V (-displaystyle V) la tension, f (-displaystyle f) la fréquence, et k (-displaystyle k) un coefficient d'ajustement, on peut calculer la puissance dissipée P (-displaystyle P) : P - k V 2 f (-displaystyle P-k-times V(2)-times f).
Ce problème est lié à un autre, celui de la dissipation thermique et donc souvent des ventilateurs, sources de nuisances sonores. Le refroidissement liquide peut être utilisé. L'utilisation d'une pâte thermique assure une meilleure conduction de la chaleur du processeur vers le radiateur. Si l'échauffement ne pose pas de problème majeur pour des applications type ordinateur de bureau, il en pose pour toutes les applications portables. Il est techniquement facile d'alimenter et de refroidir un ordinateur fixe. Pour les applications portables, ce sont deux problèmes délicats. Le téléphone portable, l'ordinateur portable, l'appareil photo numérique, le PDA, le baladeur MP3 ont une batterie qu'il s'agit de ménager pour que l'appareil portable ait une meilleure autonomie.

Prospective et innovation: Matériaux bidimensionnels : L'électronique bidimentionnelle est une piste d'innovation envisagée dès 2010. Elle s'appuie sur des microprocesseurs de taille nanométrique, imprimé en seulement deux dimensions, à partir de semi-conducteur 2D d'un ou seulement quelques atomes d'épaisseur, afin d'encore miniaturiser l'électronique sous les limites permises par le silicium. Dans les années 2010, des prototypes comprenant quelques transistors ont été testés avec succès. Des matériaux organique, des nanotubes de carbone ou le disulfure de molybdène sont des matériaux qui semblent prometteurs, notamment pour produire des composés souples, pouvant par exemple être intégrés dans des feuilles de plastique, des vêtements ou des "robots mous". Le disulfure de molybdène a été utilisé en 2017 pour fabriquer un semi-conducteur permettant de produire un microprocesseur en quasi 2D, comprenant 115 transistors. Ce dernier a efficacement exécuté des programmes stockés dans une mémoire externe (pour un bit de données mais les auteurs disent que la conception peut être mise à l'échelle pour en gérer plus). A cette échelle les microprocesseurs sont invisibles et pourraient par exemple être intégrés dans le verre de lunettes, de pare-brise ou de vitres ou dans une lentille oculaire.

Voir aussi

Articles connexes: Processeur; Liste de microprocesseurs; Chronologie des microprocesseurs; Loi de Moore; Traitement numérique (microprocesseur); Microcontrôleur; Émulateur in-circuit; Overclocking.